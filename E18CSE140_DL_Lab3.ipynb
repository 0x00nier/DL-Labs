{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [cv2.imread(file) for file in glob.glob(\"training_set/training_set/cats/cat.*.jpg\")]\n",
    "dogs = [cv2.imread(file) for file in glob.glob(\"training_set/training_set/dogs/dog.*.jpg\")]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cats\n",
      "10dogs\n",
      "23777_30378_bundle_archive.zip\n",
      "Advertising.csv\n",
      "E18CSE140_DL_Lab1.ipynb\n",
      "E18CSE140_DL_Lab2.ipynb\n",
      "E18CSE140_DL_Lab2_Part2.ipynb\n",
      "E18CSE140_DL_Lab3.ipynb\n",
      "Online Retail.xlsx\n",
      "Untitled.ipynb\n",
      "Untitled1.ipynb\n",
      "test_set\n",
      "training_set\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"10cats\"\n",
    "!mkdir \"10dogs\"\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1th cat image\n",
      "Writing 1th dog image\n",
      "Writing 2th cat image\n",
      "Writing 2th dog image\n",
      "Writing 3th cat image\n",
      "Writing 3th dog image\n",
      "Writing 4th cat image\n",
      "Writing 4th dog image\n",
      "Writing 5th cat image\n",
      "Writing 5th dog image\n",
      "Writing 6th cat image\n",
      "Writing 6th dog image\n",
      "Writing 7th cat image\n",
      "Writing 7th dog image\n",
      "Writing 8th cat image\n",
      "Writing 8th dog image\n",
      "Writing 9th cat image\n",
      "Writing 9th dog image\n",
      "Writing 10th cat image\n",
      "Writing 10th dog image\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Writing \"+str(i+1)+\"th cat image\")\n",
    "    cv2.imwrite('10cats/'+str(i+1)+'.jpg',cats[i])\n",
    "    print(\"Writing \"+str(i+1)+\"th dog image\")\n",
    "    cv2.imwrite('10dogs/'+str(i+1)+'.jpg',dogs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof of image being written - \n",
      "CATS\n",
      "1.jpg\n",
      "10.jpg\n",
      "2.jpg\n",
      "3.jpg\n",
      "4.jpg\n",
      "5.jpg\n",
      "6.jpg\n",
      "7.jpg\n",
      "8.jpg\n",
      "9.jpg\n",
      "\n",
      "DOGS\n",
      "1.jpg\n",
      "10.jpg\n",
      "2.jpg\n",
      "3.jpg\n",
      "4.jpg\n",
      "5.jpg\n",
      "6.jpg\n",
      "7.jpg\n",
      "8.jpg\n",
      "9.jpg\n"
     ]
    }
   ],
   "source": [
    "print(\"Proof of image being written - \")\n",
    "print(\"CATS\")\n",
    "!ls 10cats/\n",
    "print()\n",
    "print(\"DOGS\")\n",
    "!ls 10dogs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of cat image 1 (280, 300, 3)\n",
      "Size of cat image 2 (375, 499, 3)\n",
      "Size of cat image 3 (499, 489, 3)\n",
      "Size of cat image 4 (499, 403, 3)\n",
      "Size of cat image 5 (149, 150, 3)\n",
      "Size of cat image 6 (499, 336, 3)\n",
      "Size of cat image 7 (407, 379, 3)\n",
      "Size of cat image 8 (269, 259, 3)\n",
      "Size of cat image 9 (375, 499, 3)\n",
      "Size of cat image 10 (333, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "cats = [cv2.imread(file) for file in glob.glob(\"10cats/*.jpg\")]\n",
    "dogs = [cv2.imread(file) for file in glob.glob(\"10dogs/*.jpg\")]\n",
    "for i in range(10):\n",
    "    print(\"Size of cat image \"+str(i+1)+\" \"+str(cats[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing the Images we get - \n"
     ]
    }
   ],
   "source": [
    "print(\"Resizing the Images we get - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of cat image 1 (500, 500, 3)\n",
      "Size of cat image 2 (500, 500, 3)\n",
      "Size of cat image 3 (500, 500, 3)\n",
      "Size of cat image 4 (500, 500, 3)\n",
      "Size of cat image 5 (500, 500, 3)\n",
      "Size of cat image 6 (500, 500, 3)\n",
      "Size of cat image 7 (500, 500, 3)\n",
      "Size of cat image 8 (500, 500, 3)\n",
      "Size of cat image 9 (500, 500, 3)\n",
      "Size of cat image 10 (500, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "cats = [cv2.resize(file, (500, 500))  for file in cats]\n",
    "dogs = [cv2.resize(file, (500, 500))  for file in dogs]\n",
    "for i in range(10):\n",
    "    print(\"Size of cat image \"+str(i+1)+\" \"+str(cats[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainc=[cv2.imread(file,0) for file in glob.glob(\"training_set/training_set/cats/cat.*.jpg\")]\n",
    "traind=[cv2.imread(file,0) for file in glob.glob(\"training_set/training_set/dogs/dog.*.jpg\")]\n",
    "testc=[cv2.imread(file,0) for file in glob.glob(\"test_set/test_set/cats/cat.*.jpg\")]\n",
    "testd=[cv2.imread(file,0) for file in glob.glob(\"test_set/test_set/dogs/dog.*.jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "1011\n",
      "4005\n",
      "1012\n",
      "Shape of one image -  (280, 300)\n"
     ]
    }
   ],
   "source": [
    "print(len(trainc))\n",
    "print(len(testc))\n",
    "print(len(traind))\n",
    "print(len(testd))\n",
    "print(\"Shape of one image - \",str(trainc[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAGHAV VERMA\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "final=np.append(np.append(trainc,testc),np.append(traind,testd))\n",
    "print(len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized500 = [cv2.resize(file, (50, 50))  for file in final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized500=np.array(resized500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=resized500\n",
    "y=np.append(np.full(len(trainc)+len(testc),0),np.full(len(traind)+len(testd),1))\n",
    "y=y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10028, 50, 50)\n",
      "(10028, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train flatten (7521, 2500)\n",
      "X test flatten (2507, 2500)\n"
     ]
    }
   ],
   "source": [
    "X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2])\n",
    "X_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\n",
    "print(\"X train flatten\",X_train_flatten.shape)\n",
    "print(\"X test flatten\",X_test_flatten.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (2500, 7521)\n",
      "x test:  (2500, 2507)\n",
      "y train:  (7521,)\n",
      "y test:  (2507,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_flatten.T\n",
    "X_test = X_test_flatten.T\n",
    "y_train=y_train.T.ravel()\n",
    "y_test=y_test.T.ravel()\n",
    "print(\"x train: \",X_train.shape)\n",
    "print(\"x test: \",X_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50x50 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.7861986437973674\n",
      "test accuracy: 0.504188272836059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(random_state = 0,max_iter=2000)\n",
    "lr.fit(X_train.T,y_train.T)\n",
    "\n",
    "y_pred_test=lr.predict(X_test.T)\n",
    "y_pred_train=lr.predict(X_train.T)  \n",
    "\n",
    "print('train accuracy: {}'.format(lr.score(X_train.T,y_train.T)))\n",
    "print('test accuracy: {}'.format(lr.score(X_test.T,y_test.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75x75 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized500 = [cv2.resize(file, (75, 75))  for file in final]\n",
    "resized500=np.array(resized500)\n",
    "X=resized500\n",
    "y=np.append(np.full(len(trainc)+len(testc),0),np.full(len(traind)+len(testd),1))\n",
    "y=y.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0]\n",
    "X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2])\n",
    "X_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\n",
    "X_train = X_train_flatten.T\n",
    "X_test = X_test_flatten.T\n",
    "y_train=y_train.T.ravel()\n",
    "y_test=y_test.T.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAGHAV VERMA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 1.0\n",
      "test accuracy: 0.506980454726765\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state = 0,max_iter=2000)\n",
    "lr.fit(X_train.T,y_train.T)\n",
    "\n",
    "y_pred_test=lr.predict(X_test.T)\n",
    "y_pred_train=lr.predict(X_train.T)  \n",
    "\n",
    "print('train accuracy: {}'.format(lr.score(X_train.T,y_train.T)))\n",
    "print('test accuracy: {}'.format(lr.score(X_test.T,y_test.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25x25 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized500 = [cv2.resize(file, (25, 25))  for file in final]\n",
    "resized500=np.array(resized500)\n",
    "X=resized500\n",
    "y=np.append(np.full(len(trainc)+len(testc),0),np.full(len(traind)+len(testd),1))\n",
    "y=y.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0]\n",
    "X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2])\n",
    "X_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\n",
    "X_train = X_train_flatten.T\n",
    "X_test = X_test_flatten.T\n",
    "y_train=y_train.T.ravel()\n",
    "y_test=y_test.T.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.6378141204627045\n",
      "test accuracy: 0.5285201435979258\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state = 0,max_iter=1500)\n",
    "lr.fit(X_train.T,y_train.T)\n",
    "\n",
    "y_pred_test=lr.predict(X_test.T)\n",
    "y_pred_train=lr.predict(X_train.T)  \n",
    "\n",
    "print('train accuracy: {}'.format(lr.score(X_train.T,y_train.T)))\n",
    "print('test accuracy: {}'.format(lr.score(X_test.T,y_test.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10x10 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized500 = [cv2.resize(file, (10, 10))  for file in final]\n",
    "resized500=np.array(resized500)\n",
    "X=resized500\n",
    "y=np.append(np.full(len(trainc)+len(testc),0),np.full(len(traind)+len(testd),1))\n",
    "y=y.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0]\n",
    "X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2])\n",
    "X_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\n",
    "X_train = X_train_flatten.T\n",
    "X_test = X_test_flatten.T\n",
    "y_train=y_train.T.ravel()\n",
    "y_test=y_test.T.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.5834330541151442\n",
      "test accuracy: 0.5396888711607499\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state = 0,max_iter=1500)\n",
    "lr.fit(X_train.T,y_train.T)\n",
    "\n",
    "y_pred_test=lr.predict(X_test.T)\n",
    "y_pred_train=lr.predict(X_train.T)  \n",
    "\n",
    "print('train accuracy: {}'.format(lr.score(X_train.T,y_train.T)))\n",
    "print('test accuracy: {}'.format(lr.score(X_test.T,y_test.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100x100 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized500 = [cv2.resize(file, (100, 100))  for file in final]\n",
    "resized500=np.array(resized500)\n",
    "X=resized500\n",
    "y=np.append(np.full(len(trainc)+len(testc),0),np.full(len(traind)+len(testd),1))\n",
    "y=y.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "number_of_train = X_train.shape[0]\n",
    "number_of_test = X_test.shape[0]\n",
    "X_train_flatten = X_train.reshape(number_of_train,X_train.shape[1]*X_train.shape[2])\n",
    "X_test_flatten = X_test .reshape(number_of_test,X_test.shape[1]*X_test.shape[2])\n",
    "X_train = X_train_flatten.T\n",
    "X_test = X_test_flatten.T\n",
    "y_train=y_train.T.ravel()\n",
    "y_test=y_test.T.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAGHAV VERMA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 1.0\n",
      "test accuracy: 0.5097726366174711\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state = 0,max_iter=1500)\n",
    "lr.fit(X_train.T,y_train.T)\n",
    "\n",
    "y_pred_test=lr.predict(X_test.T)\n",
    "y_pred_train=lr.predict(X_train.T)  \n",
    "\n",
    "print('train accuracy: {}'.format(lr.score(X_train.T,y_train.T)))\n",
    "print('test accuracy: {}'.format(lr.score(X_test.T,y_test.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
