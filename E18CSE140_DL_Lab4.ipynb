{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "motivational='''\n",
    "The first and greatest victory is to conquer self Don’t stop until you’re proud.\n",
    "\n",
    "Life shrinks or expands in proportion to one’s courage. Upgrade your conviction to match your destiny.\n",
    "\n",
    "Tough times don’t last. Tough people do. It is during the hard times when the ‘hero’ within us is revealed.\n",
    "\n",
    "Our greatest glory is not in never falling, but in rising every time we fall. As long as the mind can envision the fact that you can do something, you can do it, as long as you really believe 100 percent.\n",
    "\n",
    "Don’t try to be perfect. Quitting lasts forever.\n",
    "\n",
    "Set a goal so large that you can’t achieve it until you grow into the person who can. Think about what might go right.\n",
    "\n",
    "The universe is a process. Try to be better than you were yesterday.\n",
    "\n",
    "Remember it’s just a bad day, not a bad life. Take a deep breath, stay positive and know that things will get better.\n",
    "\n",
    "The only person you are destined to become is the person you decide to be. Work hard, stay consistent, and be patient.\n",
    "\n",
    "Courage is one step ahead of fear. Upgrade your conviction to match your destiny. \n",
    "\n",
    "The path to success is to take massive, determined actions. When you face your struggles, you overcome them.\n",
    "\n",
    "Don’t think about what might go wrong. Be so good they can’t ignore you.\n",
    "\n",
    "The mind is the limit. Work hard, stay consistent, and be patient.\n",
    "\n",
    "Goals may give focus, but dreams give power. You can be anything you want to be, do anything you set out to accomplish if you hold to that desire with singleness of purpose.\n",
    "\n",
    "Use what you have. Never give up\n",
    "\n",
    "Make the most of yourself….for that is all there is of you. You have to memorize to be disciplined.\n",
    "\n",
    "The pain you feel today will be the strength you feel tomorrow. Willing is not enough; we must do.\n",
    "\n",
    "Keep going Try to be better than you were yesterday.\n",
    "\n",
    "Don’t downgrade your dream just to fit your reality. Work hard, stay consistent, and be patient.\n",
    "\n",
    "The future belongs to those who believe in the beauty of their dreams. Nothing can be done without hope and confidence. \n",
    "'''\n",
    "motivational=motivational.lower()\n",
    "motivational=motivational.split('\\n')\n",
    "motivational=list(set(motivational))\n",
    "motivational.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "demotivational='''Sex is mathematics. Individuality no longer an issue. What does intelligence signify? Define reason. Desire - meaningless. Intellect is not a cure. Justice is dead.\n",
    "Just imagine how terrible it might have been if we’d been at all competent.\n",
    "When you wish upon a falling star, your dreams can come true. Unless it's really a meteor hurtling to the Earth which will destroy all life. Then you're pretty much hosed no matter what you wish for. Unless it's death by meteorite.\n",
    "There are no stupid questions, but there are a LOT of inquisitive idiots.\n",
    "Nothing says \"you're a loser\" more than owning a motivational poster about being a winner.\n",
    "Accept that you're just a product, not a gift.\n",
    "Teach every child you meet the importance of forgiveness. It's our only hope of surviving their wrath once they realize just how badly we've screwed things up for them.\n",
    "The United States was a big country where everybody wore funny t-shirts and ate too much.\n",
    "You have to make the good out of the bad because that is all you have got to make it out of.\n",
    "You can do anything you set your mind to when you have vision, determination, and an endless supply of expendable labor.\n",
    "Happy people do not wake up for breakfast.\n",
    "Life is only logical, and to think it's a gift is depressing.\n",
    "Try & try until you cannot succeed.\n",
    "Every dead body on Mount Everest was once a highly motivated person. Stay lazy my friends. It may save your life one day.\n",
    "Furthermore, having lost faith in himself, he thought it his duty to undermine the nation's faith in itself.\n",
    "If you're not a part of the solution, there's good money to be made in prolonging the problem.\n",
    "The first step towards failure is trying.\n",
    "Those who doubt your ability probably have a valid reason.\n",
    "The best things in life are actually really expensive.\n",
    "Dream is the only way for you to escape the miserable reality of your life.'''\n",
    "demotivational=demotivational.lower()\n",
    "demotivational=demotivational.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(motivational)):\n",
    "    motivational[i]=tokenizer.tokenize(motivational[i])\n",
    "    demotivational[i]=tokenizer.tokenize(demotivational[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "demot=[]\n",
    "mot=[]\n",
    "for i in motivational:\n",
    "    tempmot=[]\n",
    "    for j in i:\n",
    "        if j not in stopWords:\n",
    "            tempmot.append(j)\n",
    "    mot.append(tempmot)\n",
    "for i in demotivational:\n",
    "    tempdemot=[]\n",
    "    for j in i:\n",
    "        if j not in stopWords:\n",
    "            tempdemot.append(j)\n",
    "    demot.append(tempdemot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mot)):\n",
    "    mot[i] = nltk.FreqDist(mot[i])\n",
    "for i in range(len(demot)):\n",
    "    demot[i] = nltk.FreqDist(demot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame.from_dict(mot)\n",
    "df1['class']=0\n",
    "df2=pd.DataFrame.from_dict(demot)\n",
    "df2['class']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([df1,df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goals</th>\n",
       "      <th>may</th>\n",
       "      <th>give</th>\n",
       "      <th>focus</th>\n",
       "      <th>dreams</th>\n",
       "      <th>power</th>\n",
       "      <th>anything</th>\n",
       "      <th>want</th>\n",
       "      <th>set</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>...</th>\n",
       "      <th>doubt</th>\n",
       "      <th>ability</th>\n",
       "      <th>probably</th>\n",
       "      <th>valid</th>\n",
       "      <th>best</th>\n",
       "      <th>actually</th>\n",
       "      <th>expensive</th>\n",
       "      <th>way</th>\n",
       "      <th>escape</th>\n",
       "      <th>miserable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    goals  may  give  focus  dreams  power  anything  want  set  accomplish  \\\n",
       "15    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "16    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "17    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "18    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "19    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "\n",
       "    ...  doubt  ability  probably  valid  best  actually  expensive  way  \\\n",
       "15  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  0.0   \n",
       "16  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  0.0   \n",
       "17  ...    1.0      1.0       1.0    1.0   0.0       0.0        0.0  0.0   \n",
       "18  ...    0.0      0.0       0.0    0.0   1.0       1.0        1.0  0.0   \n",
       "19  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  1.0   \n",
       "\n",
       "    escape  miserable  \n",
       "15     0.0        0.0  \n",
       "16     0.0        0.0  \n",
       "17     0.0        0.0  \n",
       "18     0.0        0.0  \n",
       "19     1.0        1.0  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final.drop('class',axis=1)\n",
    "                                                    , pd.get_dummies(final['class']), test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "X_test=X_test.values\n",
    "y_train=y_train.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=[8, 16, 32, 64,  128,  256,  512,1024]\n",
    "timesnodes=[]\n",
    "trainaccnodes=[]\n",
    "testaccnodes=[]\n",
    "layers=[2,3,4,5]\n",
    "timeslayers=[]\n",
    "trainacclayers=[]\n",
    "testacclayers=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 32, 8)             1976      \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 32, 2)             18        \n",
      "=================================================================\n",
      "Total params: 1,994\n",
      "Trainable params: 1,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:14,067 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_121_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:14,214 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_121_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8453 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8412 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8371 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8331 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8293 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8255 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8218 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8182 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8146 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8112 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8078 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8045 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8013 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7981 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7950 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7920 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7891 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7862 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7834 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7807 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7781 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7754 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7729 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7704 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7680 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7657 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7634 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7611 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7589 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7568 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7547 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7527 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7507 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7488 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7469 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7451 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7433 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7416 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7399 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7382 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7366 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7350 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7335 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7320 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7305 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.7291 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7277 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7251 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7238 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7226 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7214 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7202 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7190 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7179 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7168 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7157 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7147 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7137 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7127 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7117 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7108 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7099 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7090 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7081 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7073 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7065 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7057 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7049 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7041 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7034 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7027 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7020 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7013 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7006 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6999 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6993 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6987 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6981 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6975 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6969 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6963 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6958 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6952 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6947 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6942 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6937 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6927 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6905 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6901 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6897 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6893 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6889 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6881 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:15,385 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_121_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:15,517 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39AE11400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6877 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:15,570 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_121_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:15,686 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39AE11400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8013 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(16,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 32, 16)            3952      \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 32, 2)             34        \n",
      "=================================================================\n",
      "Total params: 3,986\n",
      "Trainable params: 3,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:15,853 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_123_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:16,017 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_123_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7043 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7029 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7015 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7002 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6989 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6977 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6965 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6953 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6943 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6903 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6894 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6877 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6869 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6861 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6853 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6846 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6839 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6832 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6826 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6820 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6813 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6808 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6802 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6796 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6791 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6786 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6780 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6776 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6771 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6766 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6761 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6757 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6753 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6748 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6744 - accuracy: 0.5625\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6740 - accuracy: 0.5625\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6736 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6733 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6729 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6725 - accuracy: 0.5625\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6721 - accuracy: 0.5625\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6718 - accuracy: 0.5625\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6714 - accuracy: 0.5625\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6711 - accuracy: 0.5625\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6708 - accuracy: 0.5625\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6704 - accuracy: 0.5625\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6701 - accuracy: 0.5625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6698 - accuracy: 0.5625\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6695 - accuracy: 0.5625\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6692 - accuracy: 0.5625\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6689 - accuracy: 0.5625\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6686 - accuracy: 0.5625\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6683 - accuracy: 0.5625\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6680 - accuracy: 0.5625\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6677 - accuracy: 0.5625\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6674 - accuracy: 0.5625\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6671 - accuracy: 0.5625\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6669 - accuracy: 0.5625\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6666 - accuracy: 0.5625\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6663 - accuracy: 0.5938\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6660 - accuracy: 0.5938\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6658 - accuracy: 0.5938\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6655 - accuracy: 0.5938\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6653 - accuracy: 0.5938\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6650 - accuracy: 0.6250\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6647 - accuracy: 0.6250\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6645 - accuracy: 0.6250\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6642 - accuracy: 0.6250\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6640 - accuracy: 0.6250\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6637 - accuracy: 0.6562\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6635 - accuracy: 0.6562\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6632 - accuracy: 0.6562\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6630 - accuracy: 0.6562\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6627 - accuracy: 0.6562\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6625 - accuracy: 0.6562\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6623 - accuracy: 0.6562\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6620 - accuracy: 0.6562\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6618 - accuracy: 0.6562\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6616 - accuracy: 0.6562\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6613 - accuracy: 0.6562\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6611 - accuracy: 0.6562\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6608 - accuracy: 0.6562\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6606 - accuracy: 0.6562\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6604 - accuracy: 0.6562\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6601 - accuracy: 0.6562\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6599 - accuracy: 0.6562\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6597 - accuracy: 0.6562\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6595 - accuracy: 0.6562\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6592 - accuracy: 0.6562\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6590 - accuracy: 0.6562\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6588 - accuracy: 0.6562\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6585 - accuracy: 0.6562\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6583 - accuracy: 0.6562\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6581 - accuracy: 0.6562\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6579 - accuracy: 0.6875\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6576 - accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:17,147 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_123_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:17,251 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3938C6AE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6574 - accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:17,320 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_123_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:17,452 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3938C6AE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6978 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 7,970\n",
      "Trainable params: 7,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:17,632 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_125_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:17,822 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_125_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6905 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6897 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6890 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6883 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6876 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6870 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6860 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6855 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6850 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6845 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6841 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6837 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6834 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6830 - accuracy: 0.5625\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6826 - accuracy: 0.5625\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6823 - accuracy: 0.5625\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6820 - accuracy: 0.5938\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6817 - accuracy: 0.5625\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6814 - accuracy: 0.5625\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6811 - accuracy: 0.5625\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6809 - accuracy: 0.5625\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6806 - accuracy: 0.5625\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6803 - accuracy: 0.5625\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6801 - accuracy: 0.5625\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6798 - accuracy: 0.5625\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6796 - accuracy: 0.5625\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6794 - accuracy: 0.5625\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6792 - accuracy: 0.5625\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6789 - accuracy: 0.5625\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6787 - accuracy: 0.5625\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6785 - accuracy: 0.5625\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6783 - accuracy: 0.5625\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6781 - accuracy: 0.5625\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6779 - accuracy: 0.5625\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6777 - accuracy: 0.5625\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6775 - accuracy: 0.5625\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6773 - accuracy: 0.5625\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6771 - accuracy: 0.5625\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6769 - accuracy: 0.5625\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6767 - accuracy: 0.5625\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6765 - accuracy: 0.5625\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6763 - accuracy: 0.5625\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6761 - accuracy: 0.5625\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6759 - accuracy: 0.5625\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6758 - accuracy: 0.5625\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6756 - accuracy: 0.5625\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6754 - accuracy: 0.5625\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6752 - accuracy: 0.5625\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6750 - accuracy: 0.5625\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6748 - accuracy: 0.5625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6747 - accuracy: 0.5625\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6745 - accuracy: 0.5625\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6743 - accuracy: 0.5625\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6741 - accuracy: 0.5625\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6739 - accuracy: 0.5625\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6738 - accuracy: 0.5625\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6736 - accuracy: 0.5625\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6734 - accuracy: 0.5625\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6732 - accuracy: 0.5625\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6730 - accuracy: 0.5625\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6729 - accuracy: 0.5625\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6727 - accuracy: 0.6250\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6725 - accuracy: 0.6250\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6723 - accuracy: 0.6250\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6722 - accuracy: 0.6250\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6720 - accuracy: 0.6250\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6718 - accuracy: 0.6250\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6716 - accuracy: 0.6250\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6714 - accuracy: 0.6250\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6713 - accuracy: 0.6250\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6711 - accuracy: 0.6250\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6709 - accuracy: 0.6250\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6707 - accuracy: 0.6250\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6706 - accuracy: 0.6250\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6704 - accuracy: 0.6250\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6702 - accuracy: 0.6250\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6700 - accuracy: 0.6250\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6699 - accuracy: 0.6250\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6697 - accuracy: 0.6562\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - accuracy: 0.6562\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6693 - accuracy: 0.6562\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6692 - accuracy: 0.6562\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6690 - accuracy: 0.6562\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6688 - accuracy: 0.6562\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6686 - accuracy: 0.6562\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6685 - accuracy: 0.6562\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6683 - accuracy: 0.6562\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6681 - accuracy: 0.6562\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6679 - accuracy: 0.6562\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6678 - accuracy: 0.6562\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6676 - accuracy: 0.6562\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6674 - accuracy: 0.6562\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6672 - accuracy: 0.6562\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6671 - accuracy: 0.6562\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6669 - accuracy: 0.6562\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.6562\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6665 - accuracy: 0.6562\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6664 - accuracy: 0.6562\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.65 - 0s 0s/step - loss: 0.6662 - accuracy: 0.6562\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:18,893 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_125_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:19,041 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3405C80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6660 - accuracy: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:19,094 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_125_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:19,241 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3405C80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7222 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(64,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 32, 64)            15808     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 32, 2)             130       \n",
      "=================================================================\n",
      "Total params: 15,938\n",
      "Trainable params: 15,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:19,435 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_127_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:19,580 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_127_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7033 - accuracy: 0.4375\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7029 - accuracy: 0.4375\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7025 - accuracy: 0.4375\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7022 - accuracy: 0.4375\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7019 - accuracy: 0.4688\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7016 - accuracy: 0.4688\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7013 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7010 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7008 - accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7005 - accuracy: 0.4375\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7003 - accuracy: 0.4688\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7000 - accuracy: 0.4688\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6998 - accuracy: 0.4688\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6996 - accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6993 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6991 - accuracy: 0.4688\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6989 - accuracy: 0.4688\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6987 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6984 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6982 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6980 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6978 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6976 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6974 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6971 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6969 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6967 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6965 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6963 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6961 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6959 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6957 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6955 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6952 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6950 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6948 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6946 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6944 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6942 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6938 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6934 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6927 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6925 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6919 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6907 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6904 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6902 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6900 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6898 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6896 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6894 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6892 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6890 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6888 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6886 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6884 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6882 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6880 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6878 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6876 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6874 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6871 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6869 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6867 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6863 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6861 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6859 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6857 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6855 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6853 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6851 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6849 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6847 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6845 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6843 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6841 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6839 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6837 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6835 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6833 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6831 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6829 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6827 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6825 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6823 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6820 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6818 - accuracy: 0.5625\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6816 - accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:20,764 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_127_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:20,862 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A1BAF840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6814 - accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:20,913 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_127_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:21,014 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A1BAF840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7163 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 128 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_129 (Dense)            (None, 32, 128)           31616     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 32, 2)             258       \n",
      "=================================================================\n",
      "Total params: 31,874\n",
      "Trainable params: 31,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:21,183 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_129_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:21,314 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_129_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7975 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7696 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7492 - accuracy: 0.4688\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7346 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7241 - accuracy: 0.4688\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7167 - accuracy: 0.4375\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7113 - accuracy: 0.4375\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7075 - accuracy: 0.4062\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7048 - accuracy: 0.4375\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7028 - accuracy: 0.3125\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7013 - accuracy: 0.3438\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7002 - accuracy: 0.4062\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6994 - accuracy: 0.4375\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6987 - accuracy: 0.5625\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6982 - accuracy: 0.5625\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6977 - accuracy: 0.5625\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6973 - accuracy: 0.5625\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6969 - accuracy: 0.6250\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6966 - accuracy: 0.6562\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6963 - accuracy: 0.6562\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6960 - accuracy: 0.6562\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6957 - accuracy: 0.6250\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6954 - accuracy: 0.6250\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6952 - accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6949 - accuracy: 0.6250\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6946 - accuracy: 0.6250\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6944 - accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6941 - accuracy: 0.6250\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6938 - accuracy: 0.6250\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6936 - accuracy: 0.6250\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.6250\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6925 - accuracy: 0.6250\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6920 - accuracy: 0.6250\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6918 - accuracy: 0.6250\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.6250\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.6250\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6910 - accuracy: 0.6250\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6907 - accuracy: 0.6250\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6905 - accuracy: 0.6250\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6902 - accuracy: 0.6250\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6900 - accuracy: 0.6250\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6897 - accuracy: 0.6250\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6894 - accuracy: 0.6250\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6892 - accuracy: 0.6250\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6889 - accuracy: 0.6250\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6887 - accuracy: 0.6250\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6884 - accuracy: 0.6250\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6882 - accuracy: 0.6250\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6879 - accuracy: 0.6250\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6877 - accuracy: 0.6250\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.6250\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6871 - accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6869 - accuracy: 0.6250\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6866 - accuracy: 0.6250\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6864 - accuracy: 0.6250\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6861 - accuracy: 0.6562\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6859 - accuracy: 0.6562\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6856 - accuracy: 0.6562\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6854 - accuracy: 0.6562\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6851 - accuracy: 0.6562\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6849 - accuracy: 0.6562\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6846 - accuracy: 0.6562\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6843 - accuracy: 0.6562\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6841 - accuracy: 0.6562\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6838 - accuracy: 0.6562\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6836 - accuracy: 0.6562\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6833 - accuracy: 0.6562\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6831 - accuracy: 0.6562\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6828 - accuracy: 0.6562\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6826 - accuracy: 0.6562\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6823 - accuracy: 0.6562\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6821 - accuracy: 0.6562\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6818 - accuracy: 0.6562\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6816 - accuracy: 0.6562\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6813 - accuracy: 0.6562\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6811 - accuracy: 0.6562\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6808 - accuracy: 0.6562\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6806 - accuracy: 0.6562\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6803 - accuracy: 0.6562\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6801 - accuracy: 0.6562\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6798 - accuracy: 0.6562\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6796 - accuracy: 0.6562\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6793 - accuracy: 0.6562\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6791 - accuracy: 0.6562\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6788 - accuracy: 0.6562\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6786 - accuracy: 0.6562\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6783 - accuracy: 0.6562\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6781 - accuracy: 0.6562\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6778 - accuracy: 0.6562\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6776 - accuracy: 0.6562\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6773 - accuracy: 0.6562\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6771 - accuracy: 0.6562\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6768 - accuracy: 0.6562\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6766 - accuracy: 0.6562\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6763 - accuracy: 0.6562\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6761 - accuracy: 0.6562\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6758 - accuracy: 0.6562\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:22,462 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_129_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:22,548 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39E6CF0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6756 - accuracy: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:22,617 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_129_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:22,718 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39E6CF0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7194 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(256,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 32, 256)           63232     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 32, 2)             514       \n",
      "=================================================================\n",
      "Total params: 63,746\n",
      "Trainable params: 63,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:22,865 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_131_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:22,987 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_131_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7674 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7286 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7098 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7009 - accuracy: 0.4375\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6967 - accuracy: 0.4375\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6947 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6929 - accuracy: 0.4375\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6925 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5625\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5625\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6909 - accuracy: 0.5625\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6906 - accuracy: 0.5625\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6904 - accuracy: 0.5625\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6901 - accuracy: 0.5625\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6898 - accuracy: 0.5625\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6895 - accuracy: 0.5625\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6892 - accuracy: 0.5625\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6889 - accuracy: 0.5625\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5625\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6881 - accuracy: 0.5625\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6878 - accuracy: 0.5625\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6875 - accuracy: 0.5625\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6873 - accuracy: 0.5625\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6870 - accuracy: 0.5625\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6867 - accuracy: 0.5625\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6864 - accuracy: 0.5625\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6861 - accuracy: 0.5625\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6859 - accuracy: 0.5625\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6856 - accuracy: 0.5625\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6853 - accuracy: 0.5625\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6850 - accuracy: 0.5625\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6847 - accuracy: 0.5625\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6845 - accuracy: 0.5625\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6842 - accuracy: 0.5625\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6839 - accuracy: 0.5625\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6836 - accuracy: 0.5625\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6834 - accuracy: 0.5625\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6831 - accuracy: 0.5625\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6828 - accuracy: 0.5625\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6825 - accuracy: 0.5625\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6823 - accuracy: 0.5625\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6820 - accuracy: 0.5625\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6817 - accuracy: 0.5625\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6814 - accuracy: 0.5625\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6811 - accuracy: 0.5938\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6809 - accuracy: 0.5938\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6806 - accuracy: 0.5938\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6803 - accuracy: 0.5938\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6800 - accuracy: 0.5938\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6798 - accuracy: 0.5938\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6795 - accuracy: 0.5938\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6792 - accuracy: 0.5938\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6789 - accuracy: 0.5938\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6787 - accuracy: 0.5938\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6784 - accuracy: 0.5938\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6781 - accuracy: 0.5938\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6779 - accuracy: 0.5938\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6776 - accuracy: 0.5938\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6773 - accuracy: 0.5938\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6770 - accuracy: 0.5938\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - 0s 0s/step - loss: 0.6768 - accuracy: 0.5938\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6765 - accuracy: 0.5938\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6762 - accuracy: 0.5938\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6759 - accuracy: 0.5938\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6757 - accuracy: 0.5938\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6754 - accuracy: 0.5938\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6751 - accuracy: 0.5938\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6749 - accuracy: 0.5938\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6746 - accuracy: 0.5938\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6743 - accuracy: 0.5938\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6740 - accuracy: 0.5938\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6738 - accuracy: 0.5938\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6735 - accuracy: 0.5938\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6732 - accuracy: 0.5938\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6730 - accuracy: 0.5938\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6727 - accuracy: 0.5938\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6724 - accuracy: 0.5938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6721 - accuracy: 0.5938\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6719 - accuracy: 0.5938\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6716 - accuracy: 0.5938\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6713 - accuracy: 0.5938\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6711 - accuracy: 0.5938\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6708 - accuracy: 0.5938\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.5938\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6703 - accuracy: 0.6250\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6700 - accuracy: 0.6250\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6697 - accuracy: 0.6250\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6694 - accuracy: 0.6250\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6692 - accuracy: 0.6250\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6689 - accuracy: 0.6250\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6686 - accuracy: 0.6250\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6684 - accuracy: 0.6250\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6681 - accuracy: 0.6562\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6678 - accuracy: 0.6562\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6676 - accuracy: 0.6562\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6673 - accuracy: 0.6562\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:24,109 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_131_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:24,220 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C399A302F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6670 - accuracy: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:24,267 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_131_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:24,371 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C399A302F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6982 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(512,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_133 (Dense)            (None, 32, 512)           126464    \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 32, 2)             1026      \n",
      "=================================================================\n",
      "Total params: 127,490\n",
      "Trainable params: 127,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:24,520 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_133_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:24,668 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_133_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.8427 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7290 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7104 - accuracy: 0.3438\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7078 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7072 - accuracy: 0.4375\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7068 - accuracy: 0.4375\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7065 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7061 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7058 - accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7055 - accuracy: 0.4688\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7051 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7048 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7045 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7041 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7038 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7035 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7032 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7028 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7025 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7022 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7018 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7015 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7012 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7009 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7005 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7002 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6999 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6996 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6992 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6989 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6986 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6983 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6979 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6976 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6973 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6970 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6966 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6963 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6960 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6957 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6954 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6950 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6947 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6944 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6941 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6938 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6934 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6925 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.53 - 0s 0s/step - loss: 0.6906 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6903 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6899 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6896 - accuracy: 0.5625\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6893 - accuracy: 0.5625\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6890 - accuracy: 0.5625\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5625\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6880 - accuracy: 0.5625\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6877 - accuracy: 0.5625\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6874 - accuracy: 0.5625\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6871 - accuracy: 0.5625\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6868 - accuracy: 0.5625\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5625\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6862 - accuracy: 0.5625\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6859 - accuracy: 0.5625\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6855 - accuracy: 0.5625\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6852 - accuracy: 0.5625\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6849 - accuracy: 0.5625\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6846 - accuracy: 0.5625\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6843 - accuracy: 0.5625\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6840 - accuracy: 0.5625\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6837 - accuracy: 0.5625\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6834 - accuracy: 0.5625\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6830 - accuracy: 0.5625\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6827 - accuracy: 0.5625\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6824 - accuracy: 0.5625\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6821 - accuracy: 0.5625\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6818 - accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6815 - accuracy: 0.5625\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6812 - accuracy: 0.5625\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6809 - accuracy: 0.5625\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6806 - accuracy: 0.5625\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6803 - accuracy: 0.5625\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6800 - accuracy: 0.5625\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6796 - accuracy: 0.5625\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6793 - accuracy: 0.5625\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6790 - accuracy: 0.5625\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6787 - accuracy: 0.5625\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6784 - accuracy: 0.5625\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6781 - accuracy: 0.5625\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6778 - accuracy: 0.5625\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6775 - accuracy: 0.5938\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6772 - accuracy: 0.5938\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6769 - accuracy: 0.5938\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:25,747 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_133_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:25,836 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39E4368C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6766 - accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:25,882 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_133_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:25,972 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39E4368C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7085 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1024 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 32, 1024)          252928    \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 32, 2)             2050      \n",
      "=================================================================\n",
      "Total params: 254,978\n",
      "Trainable params: 254,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:26,132 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_135_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:26,256 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_135_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7374 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6882 - accuracy: 0.5625\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6879 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6876 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6872 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6869 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6866 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6863 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6859 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6856 - accuracy: 0.5625\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6853 - accuracy: 0.5625\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6849 - accuracy: 0.5625\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6846 - accuracy: 0.5625\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6843 - accuracy: 0.5625\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6840 - accuracy: 0.5625\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6837 - accuracy: 0.5625\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6833 - accuracy: 0.5625\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6830 - accuracy: 0.5625\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6827 - accuracy: 0.5625\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6824 - accuracy: 0.5625\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6820 - accuracy: 0.5625\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6817 - accuracy: 0.5625\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6814 - accuracy: 0.5625\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6811 - accuracy: 0.5625\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6807 - accuracy: 0.5625\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6804 - accuracy: 0.5625\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6801 - accuracy: 0.5625\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6798 - accuracy: 0.5625\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6795 - accuracy: 0.5625\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6791 - accuracy: 0.5625\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6788 - accuracy: 0.5625\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6785 - accuracy: 0.5625\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6782 - accuracy: 0.5625\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6779 - accuracy: 0.5625\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6775 - accuracy: 0.5625\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6772 - accuracy: 0.5625\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6769 - accuracy: 0.5625\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6766 - accuracy: 0.5625\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6763 - accuracy: 0.5625\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6760 - accuracy: 0.5938\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6756 - accuracy: 0.5938\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6753 - accuracy: 0.5938\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6750 - accuracy: 0.5938\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6747 - accuracy: 0.5938\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6744 - accuracy: 0.5938\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6741 - accuracy: 0.5938\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6737 - accuracy: 0.5938\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6734 - accuracy: 0.5938\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6731 - accuracy: 0.6250\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6728 - accuracy: 0.6250\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6725 - accuracy: 0.6250\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.6250\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6718 - accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6715 - accuracy: 0.6250\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6712 - accuracy: 0.6250\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.6250\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6706 - accuracy: 0.6250\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6703 - accuracy: 0.6250\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6700 - accuracy: 0.6250\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6697 - accuracy: 0.6562\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6693 - accuracy: 0.6562\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6690 - accuracy: 0.6562\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6687 - accuracy: 0.6562\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6684 - accuracy: 0.6562\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6681 - accuracy: 0.6562\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6678 - accuracy: 0.6562\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6675 - accuracy: 0.6562\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6672 - accuracy: 0.6562\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6668 - accuracy: 0.6562\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6665 - accuracy: 0.6562\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6662 - accuracy: 0.6562\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6659 - accuracy: 0.6562\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6656 - accuracy: 0.6562\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6653 - accuracy: 0.6562\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6650 - accuracy: 0.6562\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6647 - accuracy: 0.6562\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6644 - accuracy: 0.6562\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6641 - accuracy: 0.6562\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6637 - accuracy: 0.6875\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6634 - accuracy: 0.6875\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6631 - accuracy: 0.6875\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6628 - accuracy: 0.6875\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6625 - accuracy: 0.6875\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6622 - accuracy: 0.6875\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6619 - accuracy: 0.6875\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6616 - accuracy: 0.6875\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6613 - accuracy: 0.6875\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6610 - accuracy: 0.6875\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6607 - accuracy: 0.6875\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6604 - accuracy: 0.6875\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6600 - accuracy: 0.6875\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6597 - accuracy: 0.6875\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6594 - accuracy: 0.6875\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6591 - accuracy: 0.6875\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6588 - accuracy: 0.6875\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6585 - accuracy: 0.6875\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6582 - accuracy: 0.6875\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6579 - accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:27,429 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_135_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:27,527 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3813400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6576 - accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:27,574 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_135_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:27,674 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3813400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7390 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_137 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 9,026\n",
      "Trainable params: 9,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:27,830 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_137_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:27,944 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_137_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7263 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7232 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7204 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7178 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7155 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7133 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7114 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7097 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7081 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7067 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7055 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7043 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7033 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7023 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7015 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7007 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7000 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6994 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6988 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6983 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6978 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6974 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6970 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6967 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6964 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6961 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6959 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6956 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6954 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6952 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6951 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6949 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6948 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6947 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6945 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6944 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6943 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6943 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6942 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6941 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6939 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6939 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6938 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6938 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6937 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6937 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.53 - 0s 0s/step - loss: 0.6937 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6935 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6935 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6935 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6935 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6934 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6934 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6934 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6934 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6934 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:29,136 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_137_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:29,232 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3915E18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:29,301 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_137_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:29,400 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3915E18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7132 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_140 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 10,082\n",
      "Trainable params: 10,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:29,617 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_140_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:29,748 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_140_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7206 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7177 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7151 - accuracy: 0.4688\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7127 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7105 - accuracy: 0.4688\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7086 - accuracy: 0.4688\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7068 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7053 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7038 - accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7026 - accuracy: 0.4688\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7014 - accuracy: 0.4688\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7003 - accuracy: 0.4688\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6994 - accuracy: 0.4688\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6986 - accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6978 - accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6971 - accuracy: 0.4688\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6965 - accuracy: 0.4688\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6959 - accuracy: 0.4688\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6954 - accuracy: 0.4688\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6950 - accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6946 - accuracy: 0.4688\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6942 - accuracy: 0.4688\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6938 - accuracy: 0.4688\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6935 - accuracy: 0.4688\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.4688\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.4375\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5625\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6926 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6920 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6919 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6910 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6910 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6910 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6910 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:30,963 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_140_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:31,083 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A305C6A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:31,136 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_140_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:31,252 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A305C6A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7113 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_144 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 11,138\n",
      "Trainable params: 11,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:31,450 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_144_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:31,584 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_144_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6927 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6925 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6920 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6919 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:32,866 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_144_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:32,957 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3246F28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:33,009 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_144_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:33,125 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3246F28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7103 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_149 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 12,194\n",
      "Trainable params: 12,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:33,366 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_149_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:33,525 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_149_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.8995 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8817 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8650 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8496 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8354 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8222 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8101 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7989 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7887 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7794 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7709 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7631 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7560 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7496 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7438 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7385 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7337 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7294 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7255 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7220 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7188 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7159 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7134 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7111 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7090 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7071 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7055 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7040 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7026 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7014 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7003 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6994 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6985 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6977 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6970 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6964 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6959 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6954 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6949 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6945 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6942 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6939 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6926 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6920 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6919 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:34,755 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_149_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:35:34,860 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3E99730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:35:34,912 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_149_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:35:35,012 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3E99730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7116 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=['2','3','4','5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=[str(i) for i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 9,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Accuracies (%)')\n",
    "width=0.3\n",
    "plt.bar(nodes,trainaccnodes,width=width,color='red',label=\"Training Accuracy\")\n",
    "plt.bar(nodes,testaccnodes,width=width,color='blue',label=\"Test Accuracy\")\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"Varying Number of Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAFKCAYAAADG0v/EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAArTklEQVR4nO3de1xUBf7/8fcwwx0E/YqmeclMtPJbStZqYhpFWmrhouIlSXPb7GK/VnJREzVRvHbF1C5mSVtCmBeyNAHLzbTUwiK1Ntd0tdZcJXVAuc35/dGj+cYqjpYzc2Bez39izpk58/4MhG/OOTPHYhiGIQAAAJPw83YAAACAX6OcAAAAU6GcAAAAU6GcAAAAU6GcAAAAU6GcAAAAU6GcAF42YsQIvfjii2csf+WVV/TAAw/87u2/+eabZ93+b3Hw4EG1b99eb731Vo3lS5Ys0YQJEy7Kc0hSXFycvvzyy4u2vXOx2+0aMmSI+vbtq/fff7/GugkTJqhPnz4qKyursbxz5846ePDgBT3P9OnTlZmZ+bvzAr6AcgJ42bBhw7RixYozlufk5Gj48OG/e/tDhw7Vn//859+9nV/4+flpzpw5+uc//3nRtulNu3fv1tGjR7V27VrddtttZ6w/dOiQZs6c6YVkgO+yeTsA4Ovi4+OVkZGh7du3q0uXLpKkTz/9VIZhqHv37lq8eLEKCgp0+vRpnTp1SqmpqYqPj1dmZqaKior0448/Kjo6WsXFxZoyZYq6d+8uSXr88ccVHR2tEydOqKSkRFOmTFFcXJwGDBigLVu26IcfftBdd92lRx99VJL04osvKjc3V6GhoerSpYsKCgpUWFh4Rt6goCCNGjVKjz32mJYvX66AgIAa6ydMmKB27dpp9OjRZ9yOi4tTv379tHXrVh0/flx/+tOf9Nlnn+mrr76SzWbTokWL1LRpU0nSG2+8oT179qiiokKjRo3SwIEDJUmFhYVatGiRKisrFRQUpNTUVHXu3LnG69G+fXvNnz+/Rq78/HwtWLBADodDoaGhmjhxosLCwjRp0iQdPnxYd911l7KzsxUUFFTjccnJyVq9erXWr1+v3r17n/F6nG2711xzjex2ux5//HHt2bNHTZo0kdVq1XXXXSdJOnz4sKZPn64ffvhBlZWV6tu3r8aMGaOqqiqlp6frs88+k7+/v1q0aKFZs2YpNDT0gn6mgLqOcgJ4mc1m0+DBg5Wbm+ssJ9nZ2Ro2bJi+//57ffzxx8rKylJQUJDWrl2r5557TvHx8ZJ+/qv+nXfekc1m06uvvqqcnBx1795ddrtdhYWFSk1N1WuvvVbj+crKyvTGG2/o8OHDio+PV2Jior777ju9/fbbys3NVXh4uB5//PFzZn7ggQe0ZcsWPf3000pNTb2gecvLy5WTk6N3331XKSkpWrlypTp06KCHHnpIK1eu1JgxYyRJgYGBWrlypQ4fPqwBAwbo2muvlb+/v55++mktW7ZMDRs21D/+8Q+NGjXKeTjm16/Hr+3du1dTp07V8uXL1bJlS23ZskUPPvig1q1bpxkzZig9PV2rV68+a95GjRpp9uzZSklJ0TXXXKNmzZqd13afe+45BQUFad26dSopKdGAAQOc5WT8+PEaOXKk4uLiVF5ervvuu0+tWrVSkyZN9Omnn+rdd9+VxWLRvHnz9PXXXysmJuaCXmOgrqOcACYwePBg9e3bV3a7XVVVVfroo480bdo0hYeHa+7cucrLy9P+/fu1c+dOlZaWOh/XqVMn5z/Ef/zjH/X888/r2LFjWrdunXr16qUGDRqc8Vy33HKLJKlp06b6n//5Hx0/flwffvih+vTp47z/8OHDtXXr1lrz+vn5ad68eUpISFBsbOwFzfrLoZOWLVuqcePG6tChgySpVatWOn78uPN+Q4YMcebs3r27tmzZIqvVqh9//FEjR4503s9isejAgQNnvB6/tnXrVnXt2lUtW7aUJHXr1k2NGjVScXGxLBaLy8yxsbEaMGCAxo8fr2XLlp3Xdrds2aJJkybJYrGoUaNGzkJZVlambdu26fjx43r22Wedy/bs2aPY2FhZrVYNGjRIsbGx6t27t6655prze2GBeoRyAphA06ZNdeONN+rdd99VWVmZevfurfDwcH311Vd68MEHNXLkSHXv3l3XX3+9nnjiCefjQkJCnF83aNBAffr00Zo1a5SXl6epU6ee9bkCAwOdX1ssFhmGIZvNpl9fZstqtbrM3KxZMz3xxBNKTU1VQkLCGdv8RWVlZY3H/fowkL+/f63b9/P7v1PiHA6HbDabqqur1a1bNz3zzDPOdT/88IOaNGmiDRs21Hg9fs3hcJxRQgzDUFVV1Tkz/Nq4ceOUlJSkxYsXn9d2f/n6F7+8pg6HQ4ZhaPny5QoODpYkHTt2TIGBgQoNDdXq1av12WefaevWrXr00Uc1evToi3LuEVCXcEIsYBLDhw9XXl6eVq1a5fzHaNu2berYsaNGjRqlG264QQUFBaqurj7nNpYtWybDMC7oL+6ePXvq/fff18mTJyVJubm55/W4Pn366Kabbqpx6Khhw4YqLi6W9PO5FZ9++ul55/i1lStXSpK+//57bdmyRd26dVO3bt20efNm7d27V5L04Ycf6s4779Tp06fPua1u3brpo48+0r/+9S9Jcp5zc+211553noCAAD355JN65ZVXnM93ru326NFDubm5cjgcOn78uAoKCiRJYWFh6tSpk5YuXSpJOnHihIYOHaqCggJt3LhRI0eOVOfOnTV27FglJCQ4X0vAl7DnBDCJP/zhD5oxY4YiIiLUvn17SVK/fv30/vvv6/bbb5fD4dDNN9+s48ePy263n3UbHTp0UEREhPOQyPnq1q2bBg8erKSkJAUFBaldu3bOv+pdmTx5snbs2OG8PWLECD322GPq3bu3WrRooa5du15Qll+Ul5drwIABqqys1OTJk9WmTRtJP78ld9y4cc49PosWLXJ5wugVV1yhqVOn6uGHH1Z1dbWCgoK0ePFihYeHX1Cmyy+/XKmpqZo8ebLL7Y4dO1ZTp07V7bffrkaNGik6Otq5nfnz5ys9PV39+/dXRUWF+vXrpzvvvFPV1dXatGmT+vXrp5CQEEVERCg9Pf0CXzmg7rMYv97vCKBOO3DggEaMGKF169add7mQpC+//FKff/65kpOTJUlLly7Vzp07axw+AQBPYc8JUE88++yzysnJ0RNPPHFBxUSS2rRpo5deekk5OTmyWCxq1qwZf7ED8Br2nAAAAFPhhFgAAGAqlBMAAGAqlBMAAGAqdeaE2CNHTno7wm/SsGGISkrKXN+xHmDW+sdX5pR8Z1ZfmVPynVnr6pxRUbW/lZ89J25ms7n+pM36glnrH1+ZU/KdWX1lTsl3Zq2Pc1JOAACAqVBOAACAqVBOAACAqVBOAACAqVBOAACAqVBOAACAqVBOAACAqVBOAACAqVBOAACAqVBOAACAqVBOAACAqdSZC/8BOLsmCxt4O8Jv8uODJ7wdAYBJsecEAACYCntOVHf/8pT46xMAUP+w5wQAAJgK5QQAAJgKh3UAAHAzTh+4MOw5AQAApkI5AQAApsJhHQB1ArvFAd9BOfExdfUXPL/cAcB3UE5QL9XVEiZRxACAc04AAICpsOcEAEyGPX/wdew5AQAApkI5AQAApkI5AQAApuLWcrJz506NGDHijOXvvPOOBg0apCFDhmjKlClyOBzujAEAAOoQt5WTl156SZMnT1Z5eXmN5adPn9YzzzyjZcuWafny5bLb7dq4caO7YgAAgDrGbeWkVatWyszMPGN5QECAli9fruDgYElSVVWVAgMD3RUDAADUMW57K3Hv3r118ODBM5b7+fmpcePGkqSsrCyVlZWpe/fuLrfXsGGIbDbrRc9Z10VFhXs7gkf4ypyS78zqK3NKzOpNZstTF3njNfTK55w4HA7NmzdP+/btU2ZmpiwWi8vHlJSUeSBZ3XPkyElvR/AIX5lT8p1ZfWVOiVlrw+e51A3u+vk9V+nxSjmZMmWKAgICtHDhQvn58YYhAADwfzxWTvLy8lRWVqaOHTsqNzdXXbp00T333CNJSk5OVnx8vKeiAAAAE3NrOWnRooVycnIkSf3793cu37NnjzufFgAA1GEcUwEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKbi1nKyc+dOjRgx4ozlhYWFSkxMVFJSknJyctwZAQAA1DE2d234pZde0po1axQcHFxjeWVlpWbNmqXc3FwFBwdr6NChuvnmmxUVFeWuKAAAoA5x256TVq1aKTMz84zle/fuVatWrRQREaGAgABdd9112r59u7tiAACAOsZte0569+6tgwcPnrHcbrcrPDzceTs0NFR2u93l9ho2DJHNZr2oGeuDqKhw13eqB3xlTsl3ZvWVOSVmrY98ZU7JO7O6rZzUJiwsTKWlpc7bpaWlNcpKbUpKytwZq846cuSktyN4hK/MKfnOrL4yp8Ss9ZGvzCm5b9ZzlR6Pv1unbdu22r9/v3766SdVVFRo+/bt6ty5s6djAAAAk/LYnpO8vDyVlZUpKSlJEyZM0OjRo2UYhhITE9W0aVNPxQAAACbn1nLSokUL51uF+/fv71weFxenuLg4dz41AACoo/gQNgAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCqUEwAAYCo2V3coLS3VJ598ov3798tisah169a68cYbFRgY6Il8AADAx9RaTk6dOqUFCxZow4YNat++vZo3by6r1arPP/9cs2bNUnx8vB588EGFhoZ6Mi8AAKjnai0n48eP1+DBg5WSkiI/v5pHfxwOhzZu3KjHHntMixYtcntIAADgO2otJ5mZmbJYLGdd5+fnp1tuuUVxcXFuCwYAAHxTrSfE/lJMDhw4oDVr1sgwDKWlpSkxMVFffvlljfsAAABcLC7frTNx4kQ5HA4VFBTou+++08SJEzVz5kxPZAMAAD7IZTkpLy9XQkKCNm7cqP79+6tLly6qqKjwRDYAAOCDXJYTq9Wq9evX64MPPlCvXr2Un59/xgmyAAAAF4vLljF9+nR98MEHmjJlipo0aaK1a9dqxowZnsgGAAB8UK3v1vn+++8lSeHh4Ro7dqxz2fjx4z2TDAAA+KRay8ndd98ti8Wi8vJyHT16VC1btpSfn5/+9a9/qUWLFlq/fr0ncwIAAB9RazkpLCyUJP3lL3/R8OHD1aVLF0nSF198oZdfftkz6QAAgM9xec7J3r17ncVEkq655hrt27fPraEAAIDvcnnhv0suuUTPPvus7rjjDhmGodWrV+uyyy7zQDQAAOCLXO45mTdvnk6cOKFx48YpJSVFVVVVmjVrlieyAQAAH+Ryz0lERITS0tIueMMOh0PTpk3T119/rYCAAM2YMUOtW7d2rl+zZo2WLl0qPz8/JSYmatiwYRf8HAAAoP5xWU7efvttzZkzRydOnJAkGYYhi8Wi3bt3n/Nx+fn5qqioUHZ2toqKijR79uwaVzCeO3eu3nnnHYWEhKhv377q27evIiIifuc4AACgrnNZThYuXKisrCxFR0df0IZ37NihHj16SJI6deqk4uLiGuvbt2+vkydPymazOQsPAACAy3LSpEmTCy4mkmS32xUWFua8bbVaVVVVJZvt56ds166dEhMTFRwcrPj4eDVo0OCc22vYMEQ2m/WCc9R3UVHh3o7gEb4yp+Q7s/rKnBKz1ke+MqfknVldlpOrr75ajzzyiLp3767AwEDn8oSEhHM+LiwsTKWlpc7bDofDWUz27NmjDz74QAUFBQoJCdH48eP13nvv6fbbb691eyUlZa6i+qQjR056O4JH+Mqcku/M6itzSsxaH/nKnJL7Zj1X6XFZTux2u0JDQ1VUVFRjuatyEhMTo40bN+qOO+5QUVFRjb0v4eHhCgoKUmBgoKxWqxo1auQ8pwUAAPg2l+Vk1qxZqqys1L59+1RdXa127do594CcS3x8vDZv3qwhQ4bIMAxlZGQoLy9PZWVlSkpKUlJSkoYNGyZ/f3+1atVKAwYMuCgDAQCAus1lyyguLtYjjzyiyMhIORwO/ec//9Hzzz+va6+99pyP8/Pz0/Tp02ssa9u2rfProUOHaujQob8xNgAAqK9clpMZM2bo6aefdpaRoqIipaenKzc31+3hAACA73H5CbFlZWU19pJ06tRJ5eXlbg0FAAB8l8tyEhERofz8fOftDRs2KDIy0p2ZAACAD3N5WCc9PV3jx4/X448/Lklq2bKl5s6d6/ZgAADAN7ksJ5dddpkWLVqkkJAQORwOHT16tMY1cgAAAC4ml4d1li1bpvvuu08hISE6fvy4xowZo+zsbE9kAwAAPshlOcnJydHf/vY3SdKll16qt99+W6+//rrbgwEAAN/kspxUVlYqICDAedvf39+tgQAAgG9zec7JrbfeqnvuuUe33367LBaL1q9fr1tuucUT2QAAgA9yWU7Gjx+vdevWadu2bbLZbEpOTtatt97qiWwAAMAHuTysI0lRUVG64oorlJKSooiICHdnAgAAPsxlOXnttdf0zDPP6NVXX1VZWZmmTJmiJUuWeCIbAADwQS7LycqVK7VkyRIFBwcrMjJSubm5WrFihSeyAQAAH+SynPj5+dV4t05gYKCsVqtbQwEAAN/l8oTYG264QXPmzNGpU6eUn5+v7Oxsde3a1RPZAACAD3K55+Svf/2rWrdurfbt22vVqlXq1auXUlNTPZENAAD4IJd7Tvz8/BQXF6chQ4Zo27Zt+uabb1RVVSWbzeVDAQAALpjLPSdTp07VM888o2+//Vbjx4/XV199pcmTJ3siGwAA8EEuy8mXX36pmTNn6r333lNiYqIyMjK0b98+T2QDAAA+yGU5qa6ulsPhUEFBgW666SadOnVKp06d8kQ2AADgg1yWk4SEBMXGxurSSy/Vtddeq8TERCUlJXkiGwAA8EEuz2odNWqU7rnnHvn5/dxjXn/9dTVq1MjtwQAAgG86r2vr/FJMJFFMAACAW51XOQEAAPAUygkAADAVl+ec7Nq1S4sXL9bx48dlGIZz+bJly9waDAAA+CaX5SQ1NVVJSUlq166dLBaLJzIBAAAf5rKcBAUF6e677/ZEFgAAANflJDY2VllZWYqNjVVgYKBzefPmzd0aDAAA+CaX5WT16tWSpKVLlzqXWSwWFRQUuC8VAADwWS7LSWFhoSdyAAAASDpHOcnMzNTYsWM1ceLEs66fNWuW20IBAADfVWs5ufrqqyVJN9xww2/asMPh0LRp0/T1118rICBAM2bMUOvWrZ3rv/jiC82ePVuGYSgqKkrz5s2rcU4LAADwTbWWk19OeB0wYECtD969e7euvPLKs67Lz89XRUWFsrOzVVRUpNmzZ2vRokWSJMMwlJaWpueee06tW7fWW2+9pUOHDunyyy//PbMAAIB6oNZysnr1ar3yyiu688471aVLFwUFBUmSTp06pW3btmnFihVq1qxZreVkx44d6tGjhySpU6dOKi4udq7bt2+fIiMj9dprr+mbb75Rz549KSYAAEDSOcpJamqq9uzZo6VLlyolJUWS5O/vr+rqat1000164IEH1KFDh1o3bLfbFRYW5rxttVpVVVUlm82mkpISff7550pLS1Pr1q01ZswYdezYUd26dat1ew0bhshms/6WGeu1qKhwb0fwCF+ZU/KdWX1lTolZ6yNfmVPyzqznfLdOhw4dNGfOHEnSsWPHZLFY1LBhw/PacFhYmEpLS523HQ6HbLafny4yMlKtW7fWFVdcIUnq0aOHiouLz1lOSkrKzut5fc2RIye9HcEjfGVOyXdm9ZU5JWatj3xlTsl9s56r9Jz3hf8aNWp03sVEkmJiYrRp0yZJUlFRkaKjo53rWrZsqdLSUu3fv1+StH37drVr1+68tw0AAOovl59z8lvFx8dr8+bNGjJkiAzDUEZGhvLy8lRWVqakpCTNnDlTKSkpMgxDnTt3Vq9evdwVBQAA1CFuKyd+fn6aPn16jWVt27Z1ft2tWzfl5ua66+kBAEAd5fKwTkVFhRYtWqS//vWvstvtWrBggSoqKjyRDQAA+CCX5WT69Ok6deqUdu3aJavVqgMHDmjSpEmeyAYAAHyQy3Ly1Vdfady4cbLZbAoODtacOXO0Z88eT2QDAAA+yGU5sVgsqqiokMVikSSVlJQ4vwYAALjYXJ4Qm5ycrFGjRunIkSOaOXOm8vPz9dBDD3kiGwAA8EEuy0lCQoI6duyoTz75RNXV1Vq0aNE5PxkWAADg9zivd+scOHBAoaGhatCggfbs2aNVq1Z5IBoAAPBFLvec3HfffTIMQ5deemmN5QkJCe7KBAAAfJjLclJSUqI1a9Z4IgsAAIDrwzpdu3bVxx9/LIfD4Yk8AADAx7ncc9K8eXPde++9zrcPG4Yhi8Wi3bt3uz0cAADwPS7LSU5OjgoLC9W8eXNP5AEAAD7O5WGdqKgoRUZGeiAKAADAeew5iYyMVL9+/RQTEyN/f3/n8lmzZrk1GAAA8E0uy0mvXr3Uq1cvD0QBAAA4Rzk5cuSIoqKi9Ic//MGTeQAAgI+rtZxMnjxZL7zwgu6++25ZLBbnu3R++W9BQYEncwIAAB9Raznp3bu3JKmwsNBjYQAAAGp9t05WVpYncwAAAEg6j7cSAwAAeFKth3X+8Y9/6JZbbjljOeecAAAAd6q1nLRu3VovvviiJ7MAAADUXk78/f116aWXejILAABA7eecxMTEeDIHAACApHOUkylTpngyBwAAgCTerQMAAEyGcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEzFbeXE4XBoypQpSkpK0ogRI7R///6z3i8tLU3z5893VwwAAFDHuK2c5Ofnq6KiQtnZ2UpJSdHs2bPPuM/y5cv1zTffuCsCAACog9xWTnbs2KEePXpIkjp16qTi4uIa6z///HPt3LlTSUlJ7ooAAADqoFov/Pd72e12hYWFOW9brVZVVVXJZrPpxx9/1IIFC7RgwQK9995757W9hg1DZLNZ3RW3zoqKCvd2BI/wlTkl35nVV+aUmLU+8pU5Je/M6rZyEhYWptLSUudth8Mhm+3np1u3bp1KSkr05z//WUeOHNHp06d1+eWX649//GOt2yspKXNX1DrtyJGT3o7gEb4yp+Q7s/rKnBKz1ke+MqfkvlnPVXrcVk5iYmK0ceNG3XHHHSoqKlJ0dLRzXXJyspKTkyVJb7/9tv75z3+es5gAAADf4bZyEh8fr82bN2vIkCEyDEMZGRnKy8tTWVkZ55kAAIBaua2c+Pn5afr06TWWtW3b9oz7sccEAAD8Gh/CBgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATIVyAgAATMXmrg07HA5NmzZNX3/9tQICAjRjxgy1bt3auf6dd97Ra6+9JqvVqujoaE2bNk1+fnQlAAB8ndvaQH5+vioqKpSdna2UlBTNnj3bue706dN65plntGzZMi1fvlx2u10bN250VxQAAFCHuK2c7NixQz169JAkderUScXFxc51AQEBWr58uYKDgyVJVVVVCgwMdFcUAABQh7jtsI7dbldYWJjzttVqVVVVlWw2m/z8/NS4cWNJUlZWlsrKytS9e/dzbq9hwxDZbFZ3xa2zoqLCvR3BI3xlTsl3ZvWVOSVmrY98ZU7JO7O6rZyEhYWptLTUedvhcMhms9W4PW/ePO3bt0+ZmZmyWCzn3F5JSZm7otZpR46c9HYEj/CVOSXfmdVX5pSYtT7ylTkl9816rtLjtsM6MTEx2rRpkySpqKhI0dHRNdZPmTJF5eXlWrhwofPwDgAAgNv2nMTHx2vz5s0aMmSIDMNQRkaG8vLyVFZWpo4dOyo3N1ddunTRPffcI0lKTk5WfHy8u+IAAIA6wm3lxM/PT9OnT6+xrG3bts6v9+zZ466nBgAAdRgfLAIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEyFcgIAAEzFbeXE4XBoypQpSkpK0ogRI7R///4a6wsLC5WYmKikpCTl5OS4KwYAAKhj3FZO8vPzVVFRoezsbKWkpGj27NnOdZWVlZo1a5ZeeeUVZWVlKTs7W0eOHHFXFAAAUIe4rZzs2LFDPXr0kCR16tRJxcXFznV79+5Vq1atFBERoYCAAF133XXavn27u6IAAIA6xG3lxG63KywszHnbarWqqqrKuS48PNy5LjQ0VHa73V1RAABAHWJz14bDwsJUWlrqvO1wOGSz2c66rrS0tEZZOZuoqHOv/z2MqYbbtm02vjKrr8wp+c6svjKn5Duz+sqckm/NejG4bc9JTEyMNm3aJEkqKipSdHS0c13btm21f/9+/fTTT6qoqND27dvVuXNnd0UBAAB1iMUwDLfUOYfDoWnTpumbb76RYRjKyMjQrl27VFZWpqSkJBUWFur555+XYRhKTEzU8OHD3REDAADUMW4rJwAAAL8FH8IGAABMhXICAABMhXICAABMxW1vJfZ1lZWVmjBhgg4dOiQ/Pz+lp6erbdu23o51Ue3cuVPz589XVlaWjh49qsmTJ+vEiROqrq7W3Llz1apVK29H/N2qq6s1efJk7du3T1arVbNmzVJpaanS09NltVoVEBCgOXPmqHHjxt6OelG88MILKiwsVGVlpYYOHapBgwZJkvLy8vT6668rOzvbywl/n1//zO7evfus38clS5Zo7dq1slgsGjNmjOLj470d+4JUVlZq0qRJOnTokCoqKvTAAw/okksu0ZgxY3TZZZdJkoYOHao77rhDH374oZ5//nlJ0lVXXaWpU6fKYrF4Mf2FS0hIcH4URYsWLTRr1ixJUkZGhtq0aaOhQ4dKkl599VWtXbtWktSzZ089/PDD3gl8gX79M7t//35NmDBBFotF7dq109SpU+Xn53fO2fbu3avBgwfr448/VmBgoLfGuHAG3GLDhg3GI488YhiGYXz00UfGww8/7OVEF9eLL75o9OvXzxg0aJBhGIaRmppqrF271jAMw9iyZYuxceNGL6a7eDZs2GBMmDDBMAzD2Lp1qzFmzBhj+PDhxq5duwzDMIw333zTyMjI8GbEi2br1q3G/fffb1RXVxt2u9147rnnDMMwjF27dhnJycnO73Vd9d8/s2f7Ph4/ftzo2bOnUV5ebvz0009Gr169vBn5N8nNzTVmzJhhGIZhHDt2zOjZs6eRk5NjLFmypMb9Tp48afTt29c4evSoYRg/vz6/fF1XnD592rjrrrtqLDt69KgxevRo45ZbbjHeeOMNwzAM48CBA8aAAQOMqqoqo7q62khKSjJ2797thcQX5r9/Zu+//35j69athmEYRlpamvH++++fc7aTJ08a9913n9G1a1fj9OnTXpvjt+Cwjpu0adNG1dXVcjgcstvtzg+gqy9atWqlzMxM5+3PPvtMhw8f1siRI5WXl6cbbrjBi+kunltvvVXp6emSpO+//16NGzfWU089pSuvvFLSz3tW6tRfI+fw0UcfKTo6Wg899JDGjBmjXr16qaSkRPPnz9ekSZO8He93+++f2bN9H4ODg9W8eXOdOnVKp06dqnN7ESSpT58++n//7/85b1utVhUXF+uDDz7Q8OHDNWnSJNntdn3++eeKjo7WnDlzNGzYMDVu3FiNGjXyYvILt2fPHp06dUr33nuvkpOTVVRUpNLSUo0dO1Z33XWX836XXHKJXn75ZVmtVvn5+amqqqpO/H/73z+zX331lfN360033aSPP/641tkMw1BaWprGjRun4OBgb43wm9WvfzFNJCQkRIcOHdLtt9+ukpISLV682NuRLqrevXvr4MGDztuHDh1SgwYN9Oqrr2rBggV66aWXavyCrMtsNptSU1O1YcMGPffcc2rSpImknwvZ66+/rr/97W9eTnhxlJSU6Pvvv9fixYt18OBBjRkzRm3bttWkSZPqxC9yV/77Z7a272OzZs3Ut29fVVdX6/777/dK1t8jNDRU0s+XCXnkkUf06KOPqqKiQoMGDVLHjh21aNEiPf/887ryyiv1ySefaNWqVQoJCdHw4cPVqVMntWnTxssTnL+goCCNHj1agwYN0nfffaf77rtP69atU8uWLZ0fAipJ/v7+atSokQzD0Ny5c3XVVVfViTn/+2fWMAxnYQ4NDdXJkydrnS0zM1M9e/ZUhw4dvBX/d2HPiZu8+uqrio2N1fr167V69WpNmDBB5eXl3o7lNpGRkYqLi5MkxcXF1bjQY30wZ84crV+/XmlpaSorK9O7776rqVOn6sUXX6xzf23WJjIyUrGxsQoICNDll1+uf//73/ruu+80bdo0jRs3Tt9++61mzpzp7ZgX1X9/Hzdt2qQff/xRBQUF+uCDD5Sfn68vvvjC2zEv2A8//KDk5GTddddd6t+/v+Lj49WxY0dJUnx8vHbt2qXIyEj97//+r6KiohQaGqouXbpo9+7dXk5+Ydq0aaM777xTFotFbdq0UWRkZK1XuC8vL9djjz2m0tJSTZ061cNJLw4/v//7J7u0tFQNGjSQdPbZ1qxZoxUrVmjEiBE6cuSI7r33Xq9k/q0oJ27SoEED50laERERqqqqUnV1tZdTuc91112nDz/8UJK0bds2XXHFFV5OdHGsWrVKL7zwgiQpODhYFotFGzZs0Ouvv66srCy1bNnSywkvnuuuu05///vfZRiGDh8+rKZNm+qdd95RVlaWnnrqKV1xxRV6/PHHvR3zolm9evUZ38eIiAgFBQUpICBAgYGBCg8P14kTJ7yc9ML85z//0b333qvx48dr4MCBkqTRo0c7S9aWLVt09dVXq2PHjvrmm2907NgxVVVVaefOnXXu/9vc3FzNnj1bknT48GHZ7XZFRUWdcT/DMPTggw+qffv2mj59uqxWq6ejXhRXXXWVPvnkE0nSpk2b1KVLl1pn27Bhg7KyspSVlaWoqCi98sor3ox+wTis4yYjR47UpEmTNGzYMFVWVuovf/mLQkJCvB3LbVJTUzV58mQtX75cYWFhevLJJ70d6aK47bbbNHHiRA0fPlxVVVWaNGmSJk2apGbNmmns2LGSpOuvv16PPPKIl5P+fjfffLO2bdumgQMHyjAMTZkypc7+EnelurpaM2fOPOv38eOPP9bgwYPl5+enmJgYde/e3ctpL8zixYt14sQJLVy4UAsXLpQkTZgwQRkZGfL391fjxo2Vnp6usLAwpaSk6E9/+pOkn89V+fU10OqCgQMHauLEiRo6dKgsFosyMjLOen5ffn6+Pv30U1VUVOjvf/+7JGncuHF17ppuqampSktL01NPPaXLL79cvXv3rjez/Tc+vh4AAJgKh3UAAICpUE4AAICpUE4AAICpUE4AAICpUE4AAICpUE4AXHQHDx5U+/bttXnz5hrL4+Lianzi5blkZmbW+OhuAL6DcgLALfz9/ZWWlia73e7tKADqGMoJALdo0qSJbrzxRs2ZM+eMdYsXL9Ydd9yh/v37a/bs2c5PT3755Zd12223KSkpqcbHxm/atEkDBw5UQkKCHn74YZWUlEj6+bICd955pxISErRgwQLPDAbA7SgnANxmwoQJ+uijj2oc3tm0aZMKCwu1YsUKrVy5Uvv379fy5cv15ZdfOpctXbpU//73vyVJx44d05NPPqklS5Zo1apVio2N1fz583Xo0CFt2rRJa9as0Ztvvqlvv/22Xl+/CvAlfHw9ALcJCwtTenq60tLStGbNGknS1q1b1bdvX+dl3BMTE7Vq1SqdPn1aPXv2dF5Vt0+fPnI4HNq5c6fzQnaS5HA4FBERoaZNmyowMFBDhgzRzTffrMcee6xeXD0ZAOUEgJvFxsbWOLzjcDjOuE9VVZUsFot+fTUNm82miooKVVdXKyYmRosXL5b08xVYS0tLZbPZ9NZbb+nTTz/Vpk2bNGTIEGVlZalNmzaeGQyA23BYB4Db/XJ458cff1TXrl21du1anT59WlVVVVqxYoW6du2qbt26aePGjTp58qTKy8u1YcMGSdK1116roqIi7du3T5K0cOFCzZ07V7t27dLdd9+t66+/XqmpqWrbtq3zPgDqNvacAHC7Xw7vjB49Wr169dKJEyeUmJioqqoqxcbG6u6775bNZtM999yjgQMHqkGDBmrevLkkKSoqShkZGXr00UflcDjUtGlTzZs3Tw0bNlSnTp3Ur18/BQcHKyYmRjfddJOXJwVwMXBVYgAAYCoc1gEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKZCOQEAAKby/wHvfShlQpCHlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Time (in seconds)')\n",
    "plt.bar(nodes,timesnodes,color='green')\n",
    "plt.title(\"Varying Number of Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Varying Number of Layers')"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Accuracies (%)')\n",
    "width=0.3\n",
    "plt.bar(layers,trainacclayers,width=width,color='red',label=\"Training Accuracy\")\n",
    "plt.bar(layers,testacclayers,width=width,color='blue',label=\"Test Accuracy\")\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"Varying Number of Layers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Time (in seconds)')\n",
    "plt.bar(nodes,timesnodes,color='green')\n",
    "plt.title(\"Varying Number of Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
