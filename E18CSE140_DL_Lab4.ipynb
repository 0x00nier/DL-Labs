{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "motivational='''\n",
    "The first and greatest victory is to conquer self Don’t stop until you’re proud.\n",
    "\n",
    "Life shrinks or expands in proportion to one’s courage. Upgrade your conviction to match your destiny.\n",
    "\n",
    "Tough times don’t last. Tough people do. It is during the hard times when the ‘hero’ within us is revealed.\n",
    "\n",
    "Our greatest glory is not in never falling, but in rising every time we fall. As long as the mind can envision the fact that you can do something, you can do it, as long as you really believe 100 percent.\n",
    "\n",
    "Don’t try to be perfect. Quitting lasts forever.\n",
    "\n",
    "Set a goal so large that you can’t achieve it until you grow into the person who can. Think about what might go right.\n",
    "\n",
    "The universe is a process. Try to be better than you were yesterday.\n",
    "\n",
    "Remember it’s just a bad day, not a bad life. Take a deep breath, stay positive and know that things will get better.\n",
    "\n",
    "The only person you are destined to become is the person you decide to be. Work hard, stay consistent, and be patient.\n",
    "\n",
    "Courage is one step ahead of fear. Upgrade your conviction to match your destiny. \n",
    "\n",
    "The path to success is to take massive, determined actions. When you face your struggles, you overcome them.\n",
    "\n",
    "Don’t think about what might go wrong. Be so good they can’t ignore you.\n",
    "\n",
    "The mind is the limit. Work hard, stay consistent, and be patient.\n",
    "\n",
    "Goals may give focus, but dreams give power. You can be anything you want to be, do anything you set out to accomplish if you hold to that desire with singleness of purpose.\n",
    "\n",
    "Use what you have. Never give up\n",
    "\n",
    "Make the most of yourself….for that is all there is of you. You have to memorize to be disciplined.\n",
    "\n",
    "The pain you feel today will be the strength you feel tomorrow. Willing is not enough; we must do.\n",
    "\n",
    "Keep going Try to be better than you were yesterday.\n",
    "\n",
    "Don’t downgrade your dream just to fit your reality. Work hard, stay consistent, and be patient.\n",
    "\n",
    "The future belongs to those who believe in the beauty of their dreams. Nothing can be done without hope and confidence. \n",
    "'''\n",
    "motivational=motivational.lower()\n",
    "motivational=motivational.split('\\n')\n",
    "motivational=list(set(motivational))\n",
    "motivational.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "demotivational='''Sex is mathematics. Individuality no longer an issue. What does intelligence signify? Define reason. Desire - meaningless. Intellect is not a cure. Justice is dead.\n",
    "Just imagine how terrible it might have been if we’d been at all competent.\n",
    "When you wish upon a falling star, your dreams can come true. Unless it's really a meteor hurtling to the Earth which will destroy all life. Then you're pretty much hosed no matter what you wish for. Unless it's death by meteorite.\n",
    "There are no stupid questions, but there are a LOT of inquisitive idiots.\n",
    "Nothing says \"you're a loser\" more than owning a motivational poster about being a winner.\n",
    "Accept that you're just a product, not a gift.\n",
    "Teach every child you meet the importance of forgiveness. It's our only hope of surviving their wrath once they realize just how badly we've screwed things up for them.\n",
    "The United States was a big country where everybody wore funny t-shirts and ate too much.\n",
    "You have to make the good out of the bad because that is all you have got to make it out of.\n",
    "You can do anything you set your mind to when you have vision, determination, and an endless supply of expendable labor.\n",
    "Happy people do not wake up for breakfast.\n",
    "Life is only logical, and to think it's a gift is depressing.\n",
    "Try & try until you cannot succeed.\n",
    "Every dead body on Mount Everest was once a highly motivated person. Stay lazy my friends. It may save your life one day.\n",
    "Furthermore, having lost faith in himself, he thought it his duty to undermine the nation's faith in itself.\n",
    "If you're not a part of the solution, there's good money to be made in prolonging the problem.\n",
    "The first step towards failure is trying.\n",
    "Those who doubt your ability probably have a valid reason.\n",
    "The best things in life are actually really expensive.\n",
    "Dream is the only way for you to escape the miserable reality of your life.'''\n",
    "demotivational=demotivational.lower()\n",
    "demotivational=demotivational.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(motivational)):\n",
    "    motivational[i]=tokenizer.tokenize(motivational[i])\n",
    "    demotivational[i]=tokenizer.tokenize(demotivational[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "demot=[]\n",
    "mot=[]\n",
    "for i in motivational:\n",
    "    tempmot=[]\n",
    "    for j in i:\n",
    "        if j not in stopWords:\n",
    "            tempmot.append(j)\n",
    "    mot.append(tempmot)\n",
    "for i in demotivational:\n",
    "    tempdemot=[]\n",
    "    for j in i:\n",
    "        if j not in stopWords:\n",
    "            tempdemot.append(j)\n",
    "    demot.append(tempdemot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mot)):\n",
    "    mot[i] = nltk.FreqDist(mot[i])\n",
    "for i in range(len(demot)):\n",
    "    demot[i] = nltk.FreqDist(demot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame.from_dict(mot)\n",
    "df1['class']=0\n",
    "df2=pd.DataFrame.from_dict(demot)\n",
    "df2['class']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([df1,df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>greatest</th>\n",
       "      <th>glory</th>\n",
       "      <th>never</th>\n",
       "      <th>falling</th>\n",
       "      <th>rising</th>\n",
       "      <th>every</th>\n",
       "      <th>time</th>\n",
       "      <th>fall</th>\n",
       "      <th>long</th>\n",
       "      <th>mind</th>\n",
       "      <th>...</th>\n",
       "      <th>doubt</th>\n",
       "      <th>ability</th>\n",
       "      <th>probably</th>\n",
       "      <th>valid</th>\n",
       "      <th>best</th>\n",
       "      <th>actually</th>\n",
       "      <th>expensive</th>\n",
       "      <th>way</th>\n",
       "      <th>escape</th>\n",
       "      <th>miserable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    greatest  glory  never  falling  rising  every  time  fall  long  mind  \\\n",
       "15       0.0    0.0    0.0      0.0     0.0    0.0   0.0   0.0   0.0   0.0   \n",
       "16       0.0    0.0    0.0      0.0     0.0    0.0   0.0   0.0   0.0   0.0   \n",
       "17       0.0    0.0    0.0      0.0     0.0    0.0   0.0   0.0   0.0   0.0   \n",
       "18       0.0    0.0    0.0      0.0     0.0    0.0   0.0   0.0   0.0   0.0   \n",
       "19       0.0    0.0    0.0      0.0     0.0    0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "    ...  doubt  ability  probably  valid  best  actually  expensive  way  \\\n",
       "15  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  0.0   \n",
       "16  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  0.0   \n",
       "17  ...    1.0      1.0       1.0    1.0   0.0       0.0        0.0  0.0   \n",
       "18  ...    0.0      0.0       0.0    0.0   1.0       1.0        1.0  0.0   \n",
       "19  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  1.0   \n",
       "\n",
       "    escape  miserable  \n",
       "15     0.0        0.0  \n",
       "16     0.0        0.0  \n",
       "17     0.0        0.0  \n",
       "18     0.0        0.0  \n",
       "19     1.0        1.0  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final.drop('class',axis=1)\n",
    "                                                    , final['class'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "X_test=X_test.values\n",
    "y_train=y_train.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=[8, 16, 32, 64,  128,  256,  512,1024]\n",
    "timesnodes=[]\n",
    "trainaccnodes=[]\n",
    "testaccnodes=[]\n",
    "layers=[2,3,4,5]\n",
    "timeslayers=[]\n",
    "trainacclayers=[]\n",
    "testacclayers=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_104 (Dense)            (None, 8)                 1976      \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.53 - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 989us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000171793222F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7684e-08 - accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(16,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_106 (Dense)            (None, 16)                3952      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,969\n",
      "Trainable params: 3,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017177812730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7684e-08 - accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_108 (Dense)            (None, 32)                7904      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 7,937\n",
      "Trainable params: 7,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 980us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 989us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017215B0F268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7684e-08 - accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(64,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 64)                15808     \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 15,873\n",
      "Trainable params: 15,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.46 - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017215B0F7B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7684e-08 - accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 128 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_112 (Dense)            (None, 128)               31616     \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,745\n",
      "Trainable params: 31,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.53 - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017215AB1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7684e-08 - accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(256,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 256)               63232     \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 63,489\n",
      "Trainable params: 63,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017215B0FF28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 995us/step - loss: 4.7684e-08 - accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(512,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 512)               126464    \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 126,977\n",
      "Trainable params: 126,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017218927EA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7684e-08 - accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1024 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 1024)              252928    \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 253,953\n",
      "Trainable params: 253,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000172159D5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7684e-08 - accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 32)                7904      \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,993\n",
      "Trainable params: 8,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 975us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.46 - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.46 - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017215B512F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7684e-08 - accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 32)                7904      \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 10,049\n",
      "Trainable params: 10,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 986us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.53 - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 983us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.53 - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000172186D7B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 983us/step - loss: 4.7684e-08 - accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 32)                7904      \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 11,105\n",
      "Trainable params: 11,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 982us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.46 - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3578e-08 - accuracy: 0.46 - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017172C92620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.4667\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7684e-08 - accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(32,activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_132 (Dense)            (None, 32)                7904      \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,161\n",
      "Trainable params: 12,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 990us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000017215D7A730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3578e-08 - accuracy: 0.5333\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7684e-08 - accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=['2','3','4','5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=[str(i) for i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "import numpy as np\n",
    "rcParams['figure.figsize'] = 9,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Varying Number of Nodes'}, xlabel='Nodes', ylabel='Training accuracy'>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.title(\"Varying Number of Nodes\")\n",
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Training accuracy')\n",
    "sns.barplot(nodes,trainaccnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Varying Number of Nodes'}, xlabel='Nodes', ylabel='Testing accuracy'>"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.title(\"Varying Number of Nodes\")\n",
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Testing accuracy')\n",
    "sns.barplot(nodes,testaccnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Varying Number of Nodes')"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Time (in seconds)')\n",
    "sns.barplot(nodes,timesnodes)\n",
    "plt.title(\"Varying Number of Nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Varying Number of layers'}, xlabel='Nodes', ylabel='Training accuracy'>"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Varying Number of layers\")\n",
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Training accuracy')\n",
    "sns.barplot(layers,trainacclayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Varying Number of layers'}, xlabel='Nodes', ylabel='Testing accuracy'>"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Varying Number of layers\")\n",
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Testing accuracy')\n",
    "sns.barplot(layers,testacclayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Varying Number of Layers')"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Time (in seconds)')\n",
    "sns.barplot(layers,timeslayers)\n",
    "plt.title(\"Varying Number of Layers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
