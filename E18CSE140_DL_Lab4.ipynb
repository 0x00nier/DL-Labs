{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "motivational='''\n",
    "The first and greatest victory is to conquer self Don’t stop until you’re proud.\n",
    "\n",
    "Life shrinks or expands in proportion to one’s courage. Upgrade your conviction to match your destiny.\n",
    "\n",
    "Tough times don’t last. Tough people do. It is during the hard times when the ‘hero’ within us is revealed.\n",
    "\n",
    "Our greatest glory is not in never falling, but in rising every time we fall. As long as the mind can envision the fact that you can do something, you can do it, as long as you really believe 100 percent.\n",
    "\n",
    "Don’t try to be perfect. Quitting lasts forever.\n",
    "\n",
    "Set a goal so large that you can’t achieve it until you grow into the person who can. Think about what might go right.\n",
    "\n",
    "The universe is a process. Try to be better than you were yesterday.\n",
    "\n",
    "Remember it’s just a bad day, not a bad life. Take a deep breath, stay positive and know that things will get better.\n",
    "\n",
    "The only person you are destined to become is the person you decide to be. Work hard, stay consistent, and be patient.\n",
    "\n",
    "Courage is one step ahead of fear. Upgrade your conviction to match your destiny. \n",
    "\n",
    "The path to success is to take massive, determined actions. When you face your struggles, you overcome them.\n",
    "\n",
    "Don’t think about what might go wrong. Be so good they can’t ignore you.\n",
    "\n",
    "The mind is the limit. Work hard, stay consistent, and be patient.\n",
    "\n",
    "Goals may give focus, but dreams give power. You can be anything you want to be, do anything you set out to accomplish if you hold to that desire with singleness of purpose.\n",
    "\n",
    "Use what you have. Never give up\n",
    "\n",
    "Make the most of yourself….for that is all there is of you. You have to memorize to be disciplined.\n",
    "\n",
    "The pain you feel today will be the strength you feel tomorrow. Willing is not enough; we must do.\n",
    "\n",
    "Keep going Try to be better than you were yesterday.\n",
    "\n",
    "Don’t downgrade your dream just to fit your reality. Work hard, stay consistent, and be patient.\n",
    "\n",
    "The future belongs to those who believe in the beauty of their dreams. Nothing can be done without hope and confidence. \n",
    "'''\n",
    "motivational=motivational.lower()\n",
    "motivational=motivational.split('\\n')\n",
    "motivational=list(set(motivational))\n",
    "motivational.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "demotivational='''Sex is mathematics. Individuality no longer an issue. What does intelligence signify? Define reason. Desire - meaningless. Intellect is not a cure. Justice is dead.\n",
    "Just imagine how terrible it might have been if we’d been at all competent.\n",
    "When you wish upon a falling star, your dreams can come true. Unless it's really a meteor hurtling to the Earth which will destroy all life. Then you're pretty much hosed no matter what you wish for. Unless it's death by meteorite.\n",
    "There are no stupid questions, but there are a LOT of inquisitive idiots.\n",
    "Nothing says \"you're a loser\" more than owning a motivational poster about being a winner.\n",
    "Accept that you're just a product, not a gift.\n",
    "Teach every child you meet the importance of forgiveness. It's our only hope of surviving their wrath once they realize just how badly we've screwed things up for them.\n",
    "The United States was a big country where everybody wore funny t-shirts and ate too much.\n",
    "You have to make the good out of the bad because that is all you have got to make it out of.\n",
    "You can do anything you set your mind to when you have vision, determination, and an endless supply of expendable labor.\n",
    "Happy people do not wake up for breakfast.\n",
    "Life is only logical, and to think it's a gift is depressing.\n",
    "Try & try until you cannot succeed.\n",
    "Every dead body on Mount Everest was once a highly motivated person. Stay lazy my friends. It may save your life one day.\n",
    "Furthermore, having lost faith in himself, he thought it his duty to undermine the nation's faith in itself.\n",
    "If you're not a part of the solution, there's good money to be made in prolonging the problem.\n",
    "The first step towards failure is trying.\n",
    "Those who doubt your ability probably have a valid reason.\n",
    "The best things in life are actually really expensive.\n",
    "Dream is the only way for you to escape the miserable reality of your life.'''\n",
    "demotivational=demotivational.lower()\n",
    "demotivational=demotivational.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(motivational)):\n",
    "    motivational[i]=tokenizer.tokenize(motivational[i])\n",
    "    demotivational[i]=tokenizer.tokenize(demotivational[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "demot=[]\n",
    "mot=[]\n",
    "for i in motivational:\n",
    "    tempmot=[]\n",
    "    for j in i:\n",
    "        if j not in stopWords:\n",
    "            tempmot.append(j)\n",
    "    mot.append(tempmot)\n",
    "for i in demotivational:\n",
    "    tempdemot=[]\n",
    "    for j in i:\n",
    "        if j not in stopWords:\n",
    "            tempdemot.append(j)\n",
    "    demot.append(tempdemot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mot)):\n",
    "    mot[i] = nltk.FreqDist(mot[i])\n",
    "for i in range(len(demot)):\n",
    "    demot[i] = nltk.FreqDist(demot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame.from_dict(mot)\n",
    "df1['class']=0\n",
    "df2=pd.DataFrame.from_dict(demot)\n",
    "df2['class']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([df1,df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goals</th>\n",
       "      <th>may</th>\n",
       "      <th>give</th>\n",
       "      <th>focus</th>\n",
       "      <th>dreams</th>\n",
       "      <th>power</th>\n",
       "      <th>anything</th>\n",
       "      <th>want</th>\n",
       "      <th>set</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>...</th>\n",
       "      <th>doubt</th>\n",
       "      <th>ability</th>\n",
       "      <th>probably</th>\n",
       "      <th>valid</th>\n",
       "      <th>best</th>\n",
       "      <th>actually</th>\n",
       "      <th>expensive</th>\n",
       "      <th>way</th>\n",
       "      <th>escape</th>\n",
       "      <th>miserable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    goals  may  give  focus  dreams  power  anything  want  set  accomplish  \\\n",
       "15    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "16    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "17    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "18    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "19    0.0  0.0   0.0    0.0     0.0    0.0       0.0   0.0  0.0         0.0   \n",
       "\n",
       "    ...  doubt  ability  probably  valid  best  actually  expensive  way  \\\n",
       "15  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  0.0   \n",
       "16  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  0.0   \n",
       "17  ...    1.0      1.0       1.0    1.0   0.0       0.0        0.0  0.0   \n",
       "18  ...    0.0      0.0       0.0    0.0   1.0       1.0        1.0  0.0   \n",
       "19  ...    0.0      0.0       0.0    0.0   0.0       0.0        0.0  1.0   \n",
       "\n",
       "    escape  miserable  \n",
       "15     0.0        0.0  \n",
       "16     0.0        0.0  \n",
       "17     0.0        0.0  \n",
       "18     0.0        0.0  \n",
       "19     1.0        1.0  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final.drop('class',axis=1)\n",
    "                                                    , pd.get_dummies(final['class']), test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "X_test=X_test.values\n",
    "y_train=y_train.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=[8, 16, 32, 64,  128,  256,  512,1024]\n",
    "timesnodes=[]\n",
    "trainaccnodes=[]\n",
    "testaccnodes=[]\n",
    "layers=[2,3,4,5]\n",
    "timeslayers=[]\n",
    "trainacclayers=[]\n",
    "testacclayers=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_86 (Dense)             (None, 32, 8)             1976      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 32, 2)             18        \n",
      "=================================================================\n",
      "Total params: 1,994\n",
      "Trainable params: 1,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:06:58,612 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_86_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:06:58,754 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_86_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7027 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7020 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7013 - accuracy: 0.4688\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7007 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7000 - accuracy: 0.4688\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6994 - accuracy: 0.4688\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6988 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6982 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6976 - accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6971 - accuracy: 0.4688\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6965 - accuracy: 0.4688\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6960 - accuracy: 0.4688\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6955 - accuracy: 0.4688\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6949 - accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6945 - accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.4688\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6935 - accuracy: 0.4688\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6930 - accuracy: 0.4688\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6926 - accuracy: 0.4688\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.4688\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.4688\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.4688\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6905 - accuracy: 0.4688\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6901 - accuracy: 0.4688\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6898 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6894 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6890 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6883 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6880 - accuracy: 0.4688\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6877 - accuracy: 0.4688\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6874 - accuracy: 0.4688\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6871 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6868 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6862 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6859 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6856 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6853 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6851 - accuracy: 0.5625\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6848 - accuracy: 0.5625\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6845 - accuracy: 0.5625\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6843 - accuracy: 0.5938\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6841 - accuracy: 0.5938\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6838 - accuracy: 0.5938\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5938\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6833 - accuracy: 0.5938\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6831 - accuracy: 0.5938\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6829 - accuracy: 0.5938\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6827 - accuracy: 0.5938\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6825 - accuracy: 0.5938\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6823 - accuracy: 0.5938\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6821 - accuracy: 0.5625\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6819 - accuracy: 0.5938\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6817 - accuracy: 0.5938\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6815 - accuracy: 0.5938\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6813 - accuracy: 0.5938\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6811 - accuracy: 0.5938\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6809 - accuracy: 0.5625\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6807 - accuracy: 0.5625\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6805 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6804 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6802 - accuracy: 0.5625\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6800 - accuracy: 0.5625\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6799 - accuracy: 0.5938\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5938\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5938\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6794 - accuracy: 0.5938\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6792 - accuracy: 0.5938\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6791 - accuracy: 0.5938\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6789 - accuracy: 0.5938\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6787 - accuracy: 0.5938\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6786 - accuracy: 0.5938\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6785 - accuracy: 0.5938\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6783 - accuracy: 0.5625\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6782 - accuracy: 0.5625\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6780 - accuracy: 0.5625\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6779 - accuracy: 0.5938\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6777 - accuracy: 0.5625\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6776 - accuracy: 0.5625\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6775 - accuracy: 0.5625\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6773 - accuracy: 0.5625\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6772 - accuracy: 0.5625\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6771 - accuracy: 0.5625\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6770 - accuracy: 0.5625\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6768 - accuracy: 0.5625\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6767 - accuracy: 0.6250\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6766 - accuracy: 0.6250\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6765 - accuracy: 0.6250\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6763 - accuracy: 0.6562\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6762 - accuracy: 0.6562\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6761 - accuracy: 0.6562\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6760 - accuracy: 0.6562\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6759 - accuracy: 0.6562\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6757 - accuracy: 0.6562\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6756 - accuracy: 0.6562\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6755 - accuracy: 0.6562\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6754 - accuracy: 0.6250\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6753 - accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:06:59,856 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_86_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:06:59,989 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39F814950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6752 - accuracy: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:00,072 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_86_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:00,219 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39F814950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7134 - accuracy: 0.1250\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(16,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 32, 16)            3952      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 32, 2)             34        \n",
      "=================================================================\n",
      "Total params: 3,986\n",
      "Trainable params: 3,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:00,381 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_88_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:00,545 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_88_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.9747 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9632 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9519 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9410 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9303 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9199 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9098 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9000 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8905 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8812 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8722 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8635 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8550 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8469 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8389 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8312 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8238 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8166 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8097 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8030 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7965 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7902 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7842 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7784 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7728 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7674 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7621 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7571 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7523 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7432 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7389 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7348 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7308 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7270 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7233 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7198 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7164 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7132 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7100 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7071 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7042 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7014 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6988 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6963 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6938 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6893 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6871 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6851 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6831 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6812 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6794 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6777 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6760 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6745 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6729 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6715 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6701 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6687 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6674 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6662 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6650 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6639 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6628 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6617 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6607 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6597 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6588 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6579 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6570 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6562 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6554 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6546 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6539 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6532 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6525 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6519 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6512 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6506 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6500 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6494 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6489 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6484 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6478 - accuracy: 0.5625\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6473 - accuracy: 0.5625\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6469 - accuracy: 0.5625\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6464 - accuracy: 0.5625\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6459 - accuracy: 0.5625\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6455 - accuracy: 0.5625\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6451 - accuracy: 0.5625\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6446 - accuracy: 0.5625\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6442 - accuracy: 0.5625\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6439 - accuracy: 0.5625\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6435 - accuracy: 0.5938\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6431 - accuracy: 0.5938\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6427 - accuracy: 0.5938\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6424 - accuracy: 0.5938\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6420 - accuracy: 0.6250\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6417 - accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:01,636 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_88_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:01,760 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C399A4B510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6414 - accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:01,823 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_88_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:01,961 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C399A4B510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7281 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 7,970\n",
      "Trainable params: 7,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:02,148 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_90_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:02,308 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_90_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8767 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8628 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8498 - accuracy: 0.4688\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8377 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8265 - accuracy: 0.4688\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8162 - accuracy: 0.4688\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8065 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7977 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7894 - accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7819 - accuracy: 0.4688\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7749 - accuracy: 0.4688\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7685 - accuracy: 0.4688\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7625 - accuracy: 0.4688\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7571 - accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7521 - accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7475 - accuracy: 0.4688\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7433 - accuracy: 0.4688\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7394 - accuracy: 0.4688\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7358 - accuracy: 0.4688\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7325 - accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7295 - accuracy: 0.4688\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7268 - accuracy: 0.4688\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7242 - accuracy: 0.4688\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7219 - accuracy: 0.4688\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7198 - accuracy: 0.4688\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7178 - accuracy: 0.4375\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7160 - accuracy: 0.4375\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7143 - accuracy: 0.4062\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7128 - accuracy: 0.4062\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7114 - accuracy: 0.4062\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7101 - accuracy: 0.4062\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7089 - accuracy: 0.4375\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7077 - accuracy: 0.4375\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7067 - accuracy: 0.4375\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7058 - accuracy: 0.3750\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7049 - accuracy: 0.3750\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7041 - accuracy: 0.4062\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7033 - accuracy: 0.3750\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7026 - accuracy: 0.4062\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7019 - accuracy: 0.3750\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7013 - accuracy: 0.4062\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7007 - accuracy: 0.4375\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7002 - accuracy: 0.4375\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6997 - accuracy: 0.4688\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6992 - accuracy: 0.4688\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6987 - accuracy: 0.4688\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6983 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6979 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6975 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6972 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6968 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6965 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6962 - accuracy: 0.5625\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6959 - accuracy: 0.5625\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6956 - accuracy: 0.5938\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6953 - accuracy: 0.5938\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6950 - accuracy: 0.5625\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6948 - accuracy: 0.5625\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6945 - accuracy: 0.5625\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6943 - accuracy: 0.5625\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6938 - accuracy: 0.5625\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5625\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6933 - accuracy: 0.5625\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5625\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5625\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6927 - accuracy: 0.5625\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6925 - accuracy: 0.5625\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5625\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5625\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6919 - accuracy: 0.5625\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.5625\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5625\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5625\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5625\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6907 - accuracy: 0.5625\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6905 - accuracy: 0.5625\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6904 - accuracy: 0.5625\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6902 - accuracy: 0.5625\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6900 - accuracy: 0.5625\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6898 - accuracy: 0.5625\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6896 - accuracy: 0.5625\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6895 - accuracy: 0.5625\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6893 - accuracy: 0.5938\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6891 - accuracy: 0.5938\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6889 - accuracy: 0.5938\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5938\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6886 - accuracy: 0.5938\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6884 - accuracy: 0.5938\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6882 - accuracy: 0.5938\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6881 - accuracy: 0.5938\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6879 - accuracy: 0.5938\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6877 - accuracy: 0.5938\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6875 - accuracy: 0.5938\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6874 - accuracy: 0.5938\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6872 - accuracy: 0.5938\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6870 - accuracy: 0.5938\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6868 - accuracy: 0.5938\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6867 - accuracy: 0.5938\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:03,379 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_90_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:03,495 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39362C268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:03,542 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_90_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:03,664 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39362C268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7051 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(64,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_92 (Dense)             (None, 32, 64)            15808     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 32, 2)             130       \n",
      "=================================================================\n",
      "Total params: 15,938\n",
      "Trainable params: 15,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:03,851 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_92_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:04,027 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_92_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7276 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7220 - accuracy: 0.4375\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7172 - accuracy: 0.4375\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7132 - accuracy: 0.4375\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7098 - accuracy: 0.4375\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.4375\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7044 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7023 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7005 - accuracy: 0.4375\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6990 - accuracy: 0.4375\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6977 - accuracy: 0.4688\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6965 - accuracy: 0.4688\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6956 - accuracy: 0.4688\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6947 - accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6927 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6922 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5625\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5625\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5625\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.5938\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6902 - accuracy: 0.6250\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6899 - accuracy: 0.6562\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6896 - accuracy: 0.6562\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6893 - accuracy: 0.6250\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6891 - accuracy: 0.6250\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6888 - accuracy: 0.6250\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6885 - accuracy: 0.6250\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6883 - accuracy: 0.6250\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6881 - accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6876 - accuracy: 0.5938\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6874 - accuracy: 0.5938\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6872 - accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6870 - accuracy: 0.5938\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6867 - accuracy: 0.5938\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5938\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6863 - accuracy: 0.5938\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6861 - accuracy: 0.6250\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6859 - accuracy: 0.6250\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6857 - accuracy: 0.6250\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6855 - accuracy: 0.6250\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6853 - accuracy: 0.6250\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6851 - accuracy: 0.6250\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6849 - accuracy: 0.6250\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6846 - accuracy: 0.6250\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6844 - accuracy: 0.6250\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6842 - accuracy: 0.6250\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6840 - accuracy: 0.6250\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6838 - accuracy: 0.6250\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6836 - accuracy: 0.6250\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6834 - accuracy: 0.6250\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6832 - accuracy: 0.6250\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6830 - accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6828 - accuracy: 0.6250\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6826 - accuracy: 0.6250\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6824 - accuracy: 0.6250\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6822 - accuracy: 0.6250\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6820 - accuracy: 0.6250\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6818 - accuracy: 0.6250\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6816 - accuracy: 0.6250\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6814 - accuracy: 0.6250\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6812 - accuracy: 0.6250\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6810 - accuracy: 0.6250\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.6250\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6806 - accuracy: 0.6250\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6804 - accuracy: 0.6250\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6802 - accuracy: 0.6250\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6800 - accuracy: 0.6250\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6798 - accuracy: 0.6250\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6796 - accuracy: 0.6250\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6794 - accuracy: 0.6250\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6792 - accuracy: 0.6250\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6790 - accuracy: 0.6250\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6788 - accuracy: 0.6250\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6786 - accuracy: 0.6250\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6784 - accuracy: 0.6250\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6782 - accuracy: 0.6250\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6780 - accuracy: 0.6250\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6778 - accuracy: 0.6250\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6776 - accuracy: 0.6562\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6774 - accuracy: 0.6562\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6772 - accuracy: 0.6562\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6770 - accuracy: 0.6875\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6768 - accuracy: 0.6875\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6766 - accuracy: 0.6875\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6764 - accuracy: 0.6875\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6762 - accuracy: 0.6875\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6760 - accuracy: 0.6875\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6758 - accuracy: 0.6875\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6756 - accuracy: 0.6875\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6754 - accuracy: 0.6875\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6752 - accuracy: 0.6875\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6750 - accuracy: 0.6875\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6748 - accuracy: 0.6875\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6746 - accuracy: 0.6875\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6744 - accuracy: 0.6875\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6742 - accuracy: 0.6875\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6740 - accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:05,283 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_92_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:05,414 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39BFEF400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6738 - accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:05,499 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_92_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:05,646 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39BFEF400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7074 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 128 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 32, 128)           31616     \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 32, 2)             258       \n",
      "=================================================================\n",
      "Total params: 31,874\n",
      "Trainable params: 31,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:05,837 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_94_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:05,968 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_94_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7969 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7719 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7538 - accuracy: 0.4688\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7408 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7316 - accuracy: 0.4375\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7251 - accuracy: 0.4375\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7204 - accuracy: 0.4375\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7171 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7146 - accuracy: 0.4375\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7129 - accuracy: 0.4062\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7116 - accuracy: 0.3438\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7106 - accuracy: 0.3750\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7098 - accuracy: 0.3750\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7092 - accuracy: 0.3750\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7087 - accuracy: 0.3750\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7083 - accuracy: 0.3750\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7079 - accuracy: 0.3750\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7075 - accuracy: 0.3750\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7072 - accuracy: 0.4062\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7069 - accuracy: 0.4062\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7066 - accuracy: 0.4375\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7063 - accuracy: 0.4375\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7060 - accuracy: 0.4375\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7058 - accuracy: 0.4375\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7055 - accuracy: 0.4375\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7052 - accuracy: 0.4375\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7050 - accuracy: 0.4375\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7047 - accuracy: 0.4375\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7044 - accuracy: 0.4375\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7042 - accuracy: 0.4375\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7039 - accuracy: 0.4375\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7036 - accuracy: 0.4375\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7034 - accuracy: 0.4375\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7031 - accuracy: 0.4375\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7028 - accuracy: 0.4688\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7026 - accuracy: 0.4688\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7023 - accuracy: 0.4688\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7021 - accuracy: 0.4688\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7018 - accuracy: 0.4688\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7015 - accuracy: 0.4688\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7013 - accuracy: 0.4688\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7010 - accuracy: 0.4688\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7007 - accuracy: 0.4688\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7005 - accuracy: 0.4688\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7002 - accuracy: 0.4688\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7000 - accuracy: 0.4688\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6997 - accuracy: 0.4688\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6994 - accuracy: 0.4688\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6992 - accuracy: 0.4688\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6989 - accuracy: 0.4688\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6987 - accuracy: 0.4688\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6984 - accuracy: 0.4688\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6981 - accuracy: 0.4688\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6979 - accuracy: 0.4688\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6976 - accuracy: 0.4688\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6974 - accuracy: 0.4688\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6971 - accuracy: 0.4688\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6969 - accuracy: 0.4688\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6966 - accuracy: 0.4688\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6963 - accuracy: 0.4688\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6961 - accuracy: 0.4688\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6958 - accuracy: 0.4688\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6956 - accuracy: 0.4688\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6953 - accuracy: 0.4688\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6951 - accuracy: 0.4688\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6948 - accuracy: 0.4688\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6945 - accuracy: 0.4688\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6943 - accuracy: 0.4688\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6935 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6920 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6910 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6907 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6905 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6902 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6900 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6897 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6892 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6890 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6882 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6880 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6877 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6875 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6872 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6870 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6867 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6862 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:07,187 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_94_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:07,303 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39E465D90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6860 - accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:07,372 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_94_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:07,472 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C39E465D90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7200 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(256,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 32, 256)           63232     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 32, 2)             514       \n",
      "=================================================================\n",
      "Total params: 63,746\n",
      "Trainable params: 63,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:07,628 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_96_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:07,750 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_96_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 1.3595 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1117 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9278 - accuracy: 0.4688\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8094 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7429 - accuracy: 0.4688\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7091 - accuracy: 0.4688\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6928 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6851 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6815 - accuracy: 0.5938\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6797 - accuracy: 0.5938\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6788 - accuracy: 0.7188\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6782 - accuracy: 0.6250\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6778 - accuracy: 0.5938\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6775 - accuracy: 0.5938\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6772 - accuracy: 0.5938\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6770 - accuracy: 0.5938\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6767 - accuracy: 0.5938\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6765 - accuracy: 0.5938\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6762 - accuracy: 0.5938\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6760 - accuracy: 0.5938\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6757 - accuracy: 0.5938\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6755 - accuracy: 0.5938\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6753 - accuracy: 0.5938\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6750 - accuracy: 0.5938\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6748 - accuracy: 0.5938\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6745 - accuracy: 0.5938\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6743 - accuracy: 0.5938\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6741 - accuracy: 0.5938\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6738 - accuracy: 0.5938\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6736 - accuracy: 0.5938\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6733 - accuracy: 0.5938\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6731 - accuracy: 0.5938\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6729 - accuracy: 0.5938\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6726 - accuracy: 0.5938\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6724 - accuracy: 0.5938\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6721 - accuracy: 0.5938\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6719 - accuracy: 0.5938\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6717 - accuracy: 0.5938\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6714 - accuracy: 0.5938\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6712 - accuracy: 0.5938\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6709 - accuracy: 0.5938\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6707 - accuracy: 0.5938\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6705 - accuracy: 0.5938\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6702 - accuracy: 0.5938\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6700 - accuracy: 0.5938\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6698 - accuracy: 0.5938\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6695 - accuracy: 0.5938\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6693 - accuracy: 0.5938\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6690 - accuracy: 0.5938\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6688 - accuracy: 0.5938\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6686 - accuracy: 0.5938\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6683 - accuracy: 0.5938\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6681 - accuracy: 0.5938\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6679 - accuracy: 0.5938\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6676 - accuracy: 0.5938\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6674 - accuracy: 0.5938\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6671 - accuracy: 0.5938\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6669 - accuracy: 0.5938\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6667 - accuracy: 0.5938\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6664 - accuracy: 0.5938\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6662 - accuracy: 0.6250\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6660 - accuracy: 0.6250\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6657 - accuracy: 0.6250\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6655 - accuracy: 0.6250\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6652 - accuracy: 0.6250\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.6250\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6648 - accuracy: 0.6250\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6645 - accuracy: 0.6250\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6643 - accuracy: 0.6250\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6641 - accuracy: 0.6250\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6638 - accuracy: 0.6562\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6636 - accuracy: 0.6875\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6634 - accuracy: 0.6875\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6631 - accuracy: 0.6875\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6629 - accuracy: 0.6875\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6626 - accuracy: 0.7188\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6624 - accuracy: 0.7188\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6622 - accuracy: 0.7188\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6619 - accuracy: 0.7188\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6617 - accuracy: 0.7188\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6615 - accuracy: 0.7188\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6612 - accuracy: 0.7188\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6610 - accuracy: 0.7188\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6608 - accuracy: 0.7188\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6605 - accuracy: 0.7188\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6603 - accuracy: 0.7188\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6601 - accuracy: 0.7188\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6598 - accuracy: 0.7188\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6596 - accuracy: 0.7188\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6594 - accuracy: 0.7188\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6591 - accuracy: 0.7188\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6589 - accuracy: 0.7188\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6586 - accuracy: 0.7188\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6584 - accuracy: 0.7188\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6582 - accuracy: 0.7188\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6579 - accuracy: 0.7188\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6577 - accuracy: 0.7188\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6575 - accuracy: 0.7188\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6572 - accuracy: 0.7188\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6570 - accuracy: 0.7188\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:09,030 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_96_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:09,138 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C399BCE488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6568 - accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:09,191 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_96_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:09,292 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C399BCE488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(512,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             (None, 32, 512)           126464    \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 32, 2)             1026      \n",
      "=================================================================\n",
      "Total params: 127,490\n",
      "Trainable params: 127,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:09,461 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_98_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:09,577 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_98_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7401 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7049 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6992 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6982 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6978 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6974 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6971 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6968 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6965 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6962 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6958 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6955 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6952 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6949 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6946 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6943 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6905 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6902 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6899 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6896 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6893 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6890 - accuracy: 0.5625\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5625\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6880 - accuracy: 0.5625\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6877 - accuracy: 0.5625\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6874 - accuracy: 0.5625\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6871 - accuracy: 0.5625\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6868 - accuracy: 0.5625\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5625\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6862 - accuracy: 0.5625\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6859 - accuracy: 0.5625\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6856 - accuracy: 0.5625\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6853 - accuracy: 0.5625\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6850 - accuracy: 0.5938\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.59 - 0s 0s/step - loss: 0.6847 - accuracy: 0.5938\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6844 - accuracy: 0.5938\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6841 - accuracy: 0.5938\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6838 - accuracy: 0.5938\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6834 - accuracy: 0.5938\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6831 - accuracy: 0.5938\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6828 - accuracy: 0.5938\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6825 - accuracy: 0.5938\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6822 - accuracy: 0.5938\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6819 - accuracy: 0.5938\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6816 - accuracy: 0.5938\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6813 - accuracy: 0.5938\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6810 - accuracy: 0.5938\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6807 - accuracy: 0.5938\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6804 - accuracy: 0.5938\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6801 - accuracy: 0.5938\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6798 - accuracy: 0.5938\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6795 - accuracy: 0.6250\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6792 - accuracy: 0.6250\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6789 - accuracy: 0.6250\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6786 - accuracy: 0.6250\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6783 - accuracy: 0.6250\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6780 - accuracy: 0.6250\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6777 - accuracy: 0.6250\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6774 - accuracy: 0.6250\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6771 - accuracy: 0.6250\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6768 - accuracy: 0.6250\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.6250\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6762 - accuracy: 0.6250\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6759 - accuracy: 0.6250\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6756 - accuracy: 0.6250\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6753 - accuracy: 0.6250\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6750 - accuracy: 0.6250\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6747 - accuracy: 0.6250\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6744 - accuracy: 0.6250\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6741 - accuracy: 0.6250\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6738 - accuracy: 0.6250\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6735 - accuracy: 0.6250\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6732 - accuracy: 0.6250\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6729 - accuracy: 0.6250\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6726 - accuracy: 0.6250\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6723 - accuracy: 0.6250\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6720 - accuracy: 0.6250\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6717 - accuracy: 0.6250\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6714 - accuracy: 0.6250\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6711 - accuracy: 0.6250\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6708 - accuracy: 0.6250\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6705 - accuracy: 0.6250\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6702 - accuracy: 0.6250\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6699 - accuracy: 0.6250\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6696 - accuracy: 0.6250\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6694 - accuracy: 0.6250\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6691 - accuracy: 0.6250\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6688 - accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:10,705 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_98_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:10,814 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C393986E18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6685 - accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:10,861 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_98_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:10,959 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C393986E18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7105 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1024 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 32, 1024)          252928    \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 32, 2)             2050      \n",
      "=================================================================\n",
      "Total params: 254,978\n",
      "Trainable params: 254,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:11,111 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_100_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:11,212 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_100_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.9636 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6965 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6958 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6954 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6951 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6947 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6944 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6940 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6926 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6919 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6905 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6901 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6898 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6894 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6891 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6884 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6880 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6877 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6873 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6870 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6866 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6863 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6859 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6856 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6852 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6849 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6845 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6842 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6838 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6835 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6831 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6828 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6825 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6821 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6818 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6814 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6811 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6807 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6804 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6800 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6797 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6794 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6790 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6787 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6783 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6780 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6777 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6773 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6770 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6766 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6763 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6760 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6756 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6753 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6749 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.53 - 0s 0s/step - loss: 0.6746 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6743 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6739 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6736 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6732 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6729 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6726 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6722 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6719 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6716 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6712 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6709 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6706 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6702 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6699 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6696 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6692 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6689 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6686 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6682 - accuracy: 0.5312\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6679 - accuracy: 0.5312\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6676 - accuracy: 0.5625\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6672 - accuracy: 0.5625\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6669 - accuracy: 0.5625\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6666 - accuracy: 0.5625\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6662 - accuracy: 0.5625\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6659 - accuracy: 0.5625\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6656 - accuracy: 0.5625\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6652 - accuracy: 0.5625\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6649 - accuracy: 0.5625\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6646 - accuracy: 0.5625\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6642 - accuracy: 0.5625\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6639 - accuracy: 0.5625\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6636 - accuracy: 0.5625\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6632 - accuracy: 0.5625\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6629 - accuracy: 0.5625\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6626 - accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timesnodes.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:12,240 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_100_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:12,314 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A2EFAD08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6623 - accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:12,361 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_100_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:12,445 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A2EFAD08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7146 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainaccnodes.append(model.evaluate(X_train,y_train)[1])\n",
    "testaccnodes.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 9,026\n",
      "Trainable params: 9,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:12,607 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_102_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:12,715 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_102_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.9079 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8890 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8713 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8549 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8398 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8258 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8130 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8012 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7904 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7805 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7715 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7634 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7559 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7492 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7431 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7376 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7326 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7281 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7240 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7204 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7171 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7142 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7115 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7092 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7070 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7051 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7034 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7019 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7005 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6993 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6982 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6973 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6964 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6956 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6949 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6943 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6937 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6920 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6909 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6907 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6905 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6904 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6902 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6901 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6899 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6898 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6897 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6896 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6896 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6895 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6894 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6893 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6893 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6892 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6892 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6891 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6891 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6891 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6890 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6890 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6890 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6889 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6889 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6889 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6888 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6888 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6888 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6888 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6887 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6886 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6886 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6886 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6886 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6886 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.53 - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6885 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6884 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6884 - accuracy: 0.5625\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6883 - accuracy: 0.5625\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6883 - accuracy: 0.5625\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6883 - accuracy: 0.5625\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6883 - accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:13,674 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_102_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:13,748 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3095598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6883 - accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:13,785 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_102_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:13,886 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A3095598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7145 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 10,082\n",
      "Trainable params: 10,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:14,068 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_105_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:14,186 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_105_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 1.2479 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2108 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1753 - accuracy: 0.4688\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1414 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1091 - accuracy: 0.4688\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0785 - accuracy: 0.4688\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0495 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0221 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9963 - accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9720 - accuracy: 0.4688\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9493 - accuracy: 0.4688\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9281 - accuracy: 0.4688\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9084 - accuracy: 0.4688\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8900 - accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8730 - accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8572 - accuracy: 0.4688\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8427 - accuracy: 0.4688\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8293 - accuracy: 0.4688\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8169 - accuracy: 0.4688\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8056 - accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7952 - accuracy: 0.4688\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7857 - accuracy: 0.4688\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7771 - accuracy: 0.4688\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7691 - accuracy: 0.4688\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7619 - accuracy: 0.4688\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.4688\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7494 - accuracy: 0.4688\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7439 - accuracy: 0.4688\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7390 - accuracy: 0.4688\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7345 - accuracy: 0.4688\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7305 - accuracy: 0.4688\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7268 - accuracy: 0.4688\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7234 - accuracy: 0.4688\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7204 - accuracy: 0.4688\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7177 - accuracy: 0.4688\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7152 - accuracy: 0.4688\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7130 - accuracy: 0.4688\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7110 - accuracy: 0.4688\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7091 - accuracy: 0.4688\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7075 - accuracy: 0.4688\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7060 - accuracy: 0.4688\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7046 - accuracy: 0.4688\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7034 - accuracy: 0.4688\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7023 - accuracy: 0.4688\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7013 - accuracy: 0.4688\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7004 - accuracy: 0.4688\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6996 - accuracy: 0.4688\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6989 - accuracy: 0.4688\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6982 - accuracy: 0.4688\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6976 - accuracy: 0.4688\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6971 - accuracy: 0.4688\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6966 - accuracy: 0.4688\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6962 - accuracy: 0.4688\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6958 - accuracy: 0.4688\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6954 - accuracy: 0.4688\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6951 - accuracy: 0.4688\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6948 - accuracy: 0.4688\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6946 - accuracy: 0.4375\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6943 - accuracy: 0.4062\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6941 - accuracy: 0.3438\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.4375\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6937 - accuracy: 0.4688\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6936 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6934 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6930 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6928 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6927 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6926 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6926 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6926 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6925 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6924 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6921 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:15,148 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_105_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:15,234 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A31217B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:15,288 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_105_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:15,388 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A31217B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7102 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 11,138\n",
      "Trainable params: 11,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:15,572 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_109_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:15,689 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_109_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.53 - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:16,663 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_109_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:16,769 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A33EF620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:16,809 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_109_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:16,922 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A33EF620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7105 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(32,input_shape=X_train.shape,activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 32, 32)            7904      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 32, 32)            1056      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 32, 2)             66        \n",
      "=================================================================\n",
      "Total params: 12,194\n",
      "Trainable params: 12,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:17,146 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_114_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:17,292 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_114_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8050 - accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7945 - accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7850 - accuracy: 0.4688\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7762 - accuracy: 0.4688\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7682 - accuracy: 0.4688\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7609 - accuracy: 0.4688\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7543 - accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7483 - accuracy: 0.4688\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7428 - accuracy: 0.4688\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7379 - accuracy: 0.4688\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7334 - accuracy: 0.4688\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7293 - accuracy: 0.4688\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7256 - accuracy: 0.4688\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7223 - accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7192 - accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7165 - accuracy: 0.4688\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7140 - accuracy: 0.4688\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7118 - accuracy: 0.4688\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7098 - accuracy: 0.4688\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7080 - accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7063 - accuracy: 0.4688\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7048 - accuracy: 0.4688\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7035 - accuracy: 0.4688\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7023 - accuracy: 0.4688\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7012 - accuracy: 0.4688\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7002 - accuracy: 0.4688\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6993 - accuracy: 0.4688\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6985 - accuracy: 0.4688\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6978 - accuracy: 0.4688\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6972 - accuracy: 0.4688\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6966 - accuracy: 0.4688\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6960 - accuracy: 0.4688\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6956 - accuracy: 0.4688\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6951 - accuracy: 0.4688\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6947 - accuracy: 0.4688\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6944 - accuracy: 0.4688\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6941 - accuracy: 0.4688\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6938 - accuracy: 0.4688\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6935 - accuracy: 0.4688\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6933 - accuracy: 0.4688\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6931 - accuracy: 0.5312\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6929 - accuracy: 0.5312\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.53 - 0s 0s/step - loss: 0.6927 - accuracy: 0.5312\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6926 - accuracy: 0.5312\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6923 - accuracy: 0.5312\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6922 - accuracy: 0.5312\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6921 - accuracy: 0.5312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6920 - accuracy: 0.5312\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.5312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6919 - accuracy: 0.5312\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6918 - accuracy: 0.5312\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6917 - accuracy: 0.5312\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6915 - accuracy: 0.5312\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5312\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6913 - accuracy: 0.5312\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "t=time.time()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "timeslayers.append(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:18,353 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_114_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (32, 246).\n",
      "2020-09-08 00:07:18,456 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A35AB950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6912 - accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-08 00:07:18,510 WARNING Model was constructed with shape (None, 32, 246) for input Tensor(\"dense_114_input:0\", shape=(None, 32, 246), dtype=float32), but it was called on an input with incompatible shape (None, 246).\n",
      "2020-09-08 00:07:18,610 WARNING 11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C3A35AB950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.7099 - accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "trainacclayers.append(model.evaluate(X_train,y_train)[1])\n",
    "testacclayers.append(model.evaluate(X_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=['2','3','4','5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=[str(i) for i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 9,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Accuracies (%)')\n",
    "width=0.3\n",
    "plt.bar(nodes,trainaccnodes,width=width,color='red',label=\"Training Accuracy\")\n",
    "plt.bar(nodes,testaccnodes,width=width,color='blue',label=\"Test Accuracy\")\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"Varying Number of Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Nodes')\n",
    "plt.ylabel('Time (in seconds)')\n",
    "plt.bar(nodes,timesnodes,color='green')\n",
    "plt.title(\"Varying Number of Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Varying Number of Layers')"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Accuracies (%)')\n",
    "width=0.3\n",
    "plt.bar(layers,trainacclayers,width=width,color='red',label=\"Training Accuracy\")\n",
    "plt.bar(layers,testacclayers,width=width,color='blue',label=\"Test Accuracy\")\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"Varying Number of Layers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Time (in seconds)')\n",
    "plt.bar(nodes,timesnodes,color='green')\n",
    "plt.title(\"Varying Number of Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
